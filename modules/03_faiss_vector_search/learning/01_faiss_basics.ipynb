{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS Basics\n",
    "\n",
    "Introduction to FAISS for efficient vector similarity search.\n",
    "\n",
    "**Learning objectives:**\n",
    "- Create and populate FAISS indexes\n",
    "- Understand IndexFlatIP vs IndexFlatL2\n",
    "- Perform basic search operations\n",
    "- Save and load indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why FAISS?\n",
    "\n",
    "Let's compare NumPy vs FAISS on a realistic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset\n",
    "n_vectors = 2_000_000\n",
    "dimension = 384\n",
    "\n",
    "# Random embeddings (simulate real embeddings)\n",
    "corpus_embeddings = np.random.randn(n_vectors, dimension).astype('float32')\n",
    "\n",
    "# Normalize (important for cosine similarity)\n",
    "norms = np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)\n",
    "corpus_embeddings = corpus_embeddings / norms\n",
    "\n",
    "print(f\"Corpus: {corpus_embeddings.shape}\")\n",
    "print(f\"Data type: {corpus_embeddings.dtype}\")\n",
    "print(f\"Memory: {corpus_embeddings.nbytes / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query\n",
    "query = np.random.randn(1, dimension).astype('float32')\n",
    "query = query / np.linalg.norm(query)\n",
    "\n",
    "print(f\"Query: {query.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy search\n",
    "start = time.time()\n",
    "similarities = np.dot(corpus_embeddings, query.T).flatten()\n",
    "top_10_indices = np.argsort(similarities)[-10:][::-1]\n",
    "numpy_time = time.time() - start\n",
    "\n",
    "print(f\"NumPy search time: {numpy_time*1000:.2f}ms\")\n",
    "print(f\"Top-10 indices: {top_10_indices}\")\n",
    "print(f\"Top-10 scores: {similarities[top_10_indices]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAISS Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS index\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product for normalized vectors\n",
    "\n",
    "# Add vectors\n",
    "index.add(corpus_embeddings)\n",
    "\n",
    "print(f\"Index size: {index.ntotal} vectors\")\n",
    "print(f\"Index type: {type(index).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS search\n",
    "start = time.time()\n",
    "distances, indices = index.search(query, k=10)\n",
    "faiss_time = time.time() - start\n",
    "\n",
    "print(f\"FAISS search time: {faiss_time*1000:.2f}ms\")\n",
    "print(f\"Speedup: {numpy_time/faiss_time:.1f}x\")\n",
    "print(f\"\\nTop-10 indices: {indices[0]}\")\n",
    "print(f\"Top-10 scores: {distances[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key observation:** FAISS is 5-20x faster even for exact search!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IndexFlatIP vs IndexFlatL2\n",
    "\n",
    "Two metrics for similarity:\n",
    "- **IndexFlatIP**: Inner Product (dot product) - for normalized vectors\n",
    "- **IndexFlatL2**: L2 Distance (Euclidean) - when magnitude matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample vectors\n",
    "vec1 = np.array([[1.0, 0.0, 0.0]], dtype='float32')\n",
    "vec2 = np.array([[0.8, 0.6, 0.0]], dtype='float32')  # Similar direction\n",
    "vec3 = np.array([[0.0, 1.0, 0.0]], dtype='float32')  # Orthogonal\n",
    "\n",
    "vectors = np.vstack([vec1, vec2, vec3])\n",
    "print(\"Vectors:\")\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IndexFlatIP (Inner Product)\n",
    "index_ip = faiss.IndexFlatIP(3)\n",
    "index_ip.add(vectors)\n",
    "\n",
    "# Search for vec1\n",
    "D_ip, I_ip = index_ip.search(vec1, k=3)\n",
    "\n",
    "print(\"IndexFlatIP (Inner Product):\")\n",
    "print(f\"Distances (higher = more similar): {D_ip[0]}\")\n",
    "print(f\"Indices: {I_ip[0]}\")\n",
    "print(\"Most similar: vec1 (itself), then vec2 (similar direction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IndexFlatL2 (Euclidean Distance)\n",
    "index_l2 = faiss.IndexFlatL2(3)\n",
    "index_l2.add(vectors)\n",
    "\n",
    "# Search for vec1\n",
    "D_l2, I_l2 = index_l2.search(vec1, k=3)\n",
    "\n",
    "print(\"IndexFlatL2 (Euclidean):\")\n",
    "print(f\"Distances (lower = more similar): {D_l2[0]}\")\n",
    "print(f\"Indices: {I_l2[0]}\")\n",
    "print(\"Same ordering as IP for normalized vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working with Real Embeddings\n",
    "\n",
    "Use sentence-transformers to generate embeddings, then search with FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Model dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents\n",
    "documents = [\n",
    "    \"How to reset my password?\",\n",
    "    \"Cannot login after password change\",\n",
    "    \"Forgot my username and password\",\n",
    "    \"Account locked after failed login attempts\",\n",
    "    \"Payment declined by bank\",\n",
    "    \"Invoice not received in email\",\n",
    "    \"Refund processing time\",\n",
    "    \"How to update billing address\",\n",
    "    \"Cannot download invoice PDF\",\n",
    "    \"Subscription cancellation process\",\n",
    "]\n",
    "\n",
    "print(f\"Total documents: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "embeddings = model.encode(\n",
    "    documents,\n",
    "    normalize_embeddings=True,  # L2 normalization for IndexFlatIP\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# Convert to float32 (required by FAISS)\n",
    "embeddings = embeddings.astype('float32')\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embeddings dtype: {embeddings.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "# Add embeddings\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"Index contains {index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with text query\n",
    "query_text = \"I can't remember my password\"\n",
    "\n",
    "# Encode query\n",
    "query_embedding = model.encode(\n",
    "    query_text,\n",
    "    normalize_embeddings=True\n",
    ").astype('float32')\n",
    "\n",
    "# Ensure 2D shape\n",
    "query_embedding = query_embedding.reshape(1, -1)\n",
    "\n",
    "# Search\n",
    "k = 3\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "print(f\"Query: {query_text}\\n\")\n",
    "print(\"Top 3 results:\")\n",
    "for i, (score, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "    print(f\"{i+1}. [{score:.3f}] {documents[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Batch Search\n",
    "\n",
    "Search multiple queries at once for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple queries\n",
    "queries = [\n",
    "    \"password reset\",\n",
    "    \"billing problem\",\n",
    "    \"account locked\"\n",
    "]\n",
    "\n",
    "# Encode batch\n",
    "query_embeddings = model.encode(\n",
    "    queries,\n",
    "    normalize_embeddings=True\n",
    ").astype('float32')\n",
    "\n",
    "print(f\"Query batch shape: {query_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch search\n",
    "D, I = index.search(query_embeddings, k=2)\n",
    "\n",
    "print(\"Batch search results:\\n\")\n",
    "for i, query in enumerate(queries):\n",
    "    print(f\"Query: {query}\")\n",
    "    for score, idx in zip(D[i], I[i]):\n",
    "        print(f\"  [{score:.3f}] {documents[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save and Load Index\n",
    "\n",
    "Persist index to disk for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index\n",
    "faiss.write_index(index, \"my_index.faiss\")\n",
    "print(\"Index saved to my_index.faiss\")\n",
    "\n",
    "# Check file size\n",
    "import os\n",
    "size_bytes = os.path.getsize(\"my_index.faiss\")\n",
    "print(f\"File size: {size_bytes / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index\n",
    "loaded_index = faiss.read_index(\"my_index.faiss\")\n",
    "\n",
    "print(f\"Loaded index size: {loaded_index.ntotal}\")\n",
    "print(f\"Dimension: {loaded_index.d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify it works\n",
    "D_loaded, I_loaded = loaded_index.search(query_embedding, k=3)\n",
    "\n",
    "print(\"Search with loaded index:\")\n",
    "for i, (score, idx) in enumerate(zip(D_loaded[0], I_loaded[0])):\n",
    "    print(f\"{i+1}. [{score:.3f}] {documents[idx]}\")\n",
    "\n",
    "# Should be identical to original results\n",
    "assert np.array_equal(I_loaded, indices), \"Results should match!\"\n",
    "print(\"\\n✓ Results match original index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Common Pitfalls\n",
    "\n",
    "Avoid these mistakes when using FAISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❌ WRONG: Using float64\n",
    "try:\n",
    "    bad_embeddings = np.random.randn(10, 384)  # float64\n",
    "    index.add(bad_embeddings)\n",
    "except Exception as e:\n",
    "    print(f\"Error with float64: {e}\")\n",
    "\n",
    "# ✓ CORRECT: Use float32\n",
    "good_embeddings = np.random.randn(10, 384).astype('float32')\n",
    "index.add(good_embeddings)\n",
    "print(f\"\\n✓ Added with float32. Index size: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❌ WRONG: 1D query\n",
    "try:\n",
    "    query_1d = np.random.randn(384).astype('float32')\n",
    "    index.search(query_1d, k=5)\n",
    "except Exception as e:\n",
    "    print(f\"Error with 1D query: {type(e).__name__}\")\n",
    "\n",
    "# ✓ CORRECT: 2D query (n_queries, dimension)\n",
    "query_2d = np.random.randn(1, 384).astype('float32')\n",
    "D, I = index.search(query_2d, k=5)\n",
    "print(f\"\\n✓ Search with 2D query succeeded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key takeaways:\n",
    "1. FAISS is 5-20x faster than NumPy for similarity search\n",
    "2. Use `IndexFlatIP` for normalized embeddings (cosine similarity)\n",
    "3. Always use `float32` and 2D arrays `(n, dimension)`\n",
    "4. Batch queries for better efficiency\n",
    "5. Save indexes to disk for reuse\n",
    "\n",
    "**Next:** Learn about approximate search with IVF and HNSW indexes!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
