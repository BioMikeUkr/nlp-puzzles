{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS Indexes: IVF and HNSW\n",
    "\n",
    "Learn about approximate indexes for faster search on large datasets.\n",
    "\n",
    "**Learning objectives:**\n",
    "- Understand IVF (Inverted File) index\n",
    "- Work with HNSW (Hierarchical Navigable Small World) index\n",
    "- Compare performance vs accuracy trade-offs\n",
    "- Choose the right index for your use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Generate Large Dataset\n",
    "\n",
    "Create dataset where Flat index becomes slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large corpus\n",
    "n_vectors = 500_000  # 500K vectors\n",
    "dimension = 384\n",
    "\n",
    "print(\"Generating corpus...\")\n",
    "corpus = np.random.randn(n_vectors, dimension).astype('float32')\n",
    "faiss.normalize_L2(corpus)  # In-place normalization\n",
    "\n",
    "print(f\"Corpus: {corpus.shape}\")\n",
    "print(f\"Memory: {corpus.nbytes / 1e9:.2f} GB\")\n",
    "\n",
    "# Test queries\n",
    "n_queries = 100\n",
    "queries = np.random.randn(n_queries, dimension).astype('float32')\n",
    "faiss.normalize_L2(queries)\n",
    "\n",
    "print(f\"Queries: {queries.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline: IndexFlatIP\n",
    "\n",
    "Exact search - 100% accurate but slow on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flat index\n",
    "index_flat = faiss.IndexFlatIP(dimension)\n",
    "index_flat.add(corpus)\n",
    "\n",
    "print(f\"Index size: {index_flat.ntotal:,} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark flat index\n",
    "k = 10\n",
    "\n",
    "start = time.time()\n",
    "D_flat, I_flat = index_flat.search(queries, k)\n",
    "time_flat = (time.time() - start) / len(queries) * 1000  # ms per query\n",
    "\n",
    "print(f\"IndexFlatIP: {time_flat:.2f} ms/query\")\n",
    "print(f\"Total time for {len(queries)} queries: {time_flat * len(queries):.0f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IVF Index (Inverted File)\n",
    "\n",
    "Approximate search using clustering.\n",
    "\n",
    "**How it works:**\n",
    "1. Cluster vectors into `nlist` groups\n",
    "2. At search time, only check `nprobe` closest clusters\n",
    "3. Much faster, slight accuracy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IVF index\n",
    "nlist = 1000  # Number of clusters\n",
    "\n",
    "# Step 1: Create quantizer (for clustering)\n",
    "quantizer = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "# Step 2: Create IVF index\n",
    "index_ivf = faiss.IndexIVFFlat(\n",
    "    quantizer,\n",
    "    dimension,\n",
    "    nlist,\n",
    "    faiss.METRIC_INNER_PRODUCT\n",
    ")\n",
    "\n",
    "print(f\"Created IVF index with nlist={nlist}\")\n",
    "print(f\"Is trained: {index_ivf.is_trained}\")  # Should be False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train (learn cluster centroids)\n",
    "print(\"Training IVF index...\")\n",
    "start = time.time()\n",
    "\n",
    "# Use sample for training (faster)\n",
    "train_size = min(100_000, len(corpus))\n",
    "index_ivf.train(corpus[:train_size])\n",
    "\n",
    "train_time = time.time() - start\n",
    "print(f\"Training took {train_time:.1f}s\")\n",
    "print(f\"Is trained: {index_ivf.is_trained}\")  # Should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Add vectors\n",
    "print(\"Adding vectors to IVF index...\")\n",
    "start = time.time()\n",
    "index_ivf.add(corpus)\n",
    "add_time = time.time() - start\n",
    "\n",
    "print(f\"Added {index_ivf.ntotal:,} vectors in {add_time:.1f}s\")\n",
    "print(f\"Avg vectors per cluster: {index_ivf.ntotal / nlist:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning nprobe\n",
    "\n",
    "Control speed vs accuracy trade-off with `nprobe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different nprobe values\n",
    "nprobe_values = [1, 5, 10, 20, 50]\n",
    "results = []\n",
    "\n",
    "for nprobe in nprobe_values:\n",
    "    index_ivf.nprobe = nprobe\n",
    "\n",
    "    # Measure search time\n",
    "    start = time.time()\n",
    "    D_ivf, I_ivf = index_ivf.search(queries, k)\n",
    "    search_time = (time.time() - start) / len(queries) * 1000\n",
    "\n",
    "    # Calculate recall@k\n",
    "    recall = 0\n",
    "    for i in range(len(queries)):\n",
    "        true_set = set(I_flat[i])\n",
    "        pred_set = set(I_ivf[i])\n",
    "        recall += len(true_set & pred_set) / k\n",
    "    recall /= len(queries)\n",
    "\n",
    "    results.append({\n",
    "        'nprobe': nprobe,\n",
    "        'time': search_time,\n",
    "        'recall': recall\n",
    "    })\n",
    "\n",
    "    print(f\"nprobe={nprobe:3d}: {search_time:6.2f} ms/query, recall={recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Latency vs nprobe\n",
    "ax1.plot([r['nprobe'] for r in results], [r['time'] for r in results], 'o-')\n",
    "ax1.axhline(time_flat, color='r', linestyle='--', label='Flat index')\n",
    "ax1.set_xlabel('nprobe')\n",
    "ax1.set_ylabel('Latency (ms/query)')\n",
    "ax1.set_title('Search Speed vs nprobe')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Recall vs nprobe\n",
    "ax2.plot([r['nprobe'] for r in results], [r['recall'] for r in results], 'o-')\n",
    "ax2.axhline(1.0, color='r', linestyle='--', label='Perfect recall')\n",
    "ax2.set_xlabel('nprobe')\n",
    "ax2.set_ylabel('Recall@10')\n",
    "ax2.set_title('Recall vs nprobe')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key insight:** `nprobe=10` gives ~95% recall with 5-10x speedup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HNSW Index\n",
    "\n",
    "Graph-based approximate search.\n",
    "\n",
    "**Advantages:**\n",
    "- Very fast (< 1ms per query)\n",
    "- High recall (95-99%)\n",
    "- No training needed\n",
    "\n",
    "**Disadvantages:**\n",
    "- Higher memory usage\n",
    "- No deletion support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HNSW index\n",
    "M = 8  # Number of connections per layer\n",
    "\n",
    "index_hnsw = faiss.IndexHNSWFlat(dimension, M)\n",
    "index_hnsw.hnsw.efConstruction = 64  # Build quality (set before adding)\n",
    "\n",
    "print(f\"Created HNSW with M={M}\")\n",
    "print(f\"efConstruction={index_hnsw.hnsw.efConstruction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vectors (no training needed!)\n",
    "print(\"Building HNSW index...\")\n",
    "start = time.time()\n",
    "index_hnsw.add(corpus)\n",
    "build_time = time.time() - start\n",
    "\n",
    "print(f\"Built index with {index_hnsw.ntotal:,} vectors in {build_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning efSearch\n",
    "\n",
    "Control search quality with `efSearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different efSearch values\n",
    "efSearch_values = [16, 32, 64, 128, 256]\n",
    "hnsw_results = []\n",
    "\n",
    "for efSearch in efSearch_values:\n",
    "    index_hnsw.hnsw.efSearch = efSearch\n",
    "\n",
    "    # Measure search time\n",
    "    start = time.time()\n",
    "    D_hnsw, I_hnsw = index_hnsw.search(queries, k)\n",
    "    search_time = (time.time() - start) / len(queries) * 1000\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = 0\n",
    "    for i in range(len(queries)):\n",
    "        true_set = set(I_flat[i])\n",
    "        pred_set = set(I_hnsw[i])\n",
    "        recall += len(true_set & pred_set) / k\n",
    "    recall /= len(queries)\n",
    "\n",
    "    hnsw_results.append({\n",
    "        'efSearch': efSearch,\n",
    "        'time': search_time,\n",
    "        'recall': recall\n",
    "    })\n",
    "\n",
    "    print(f\"efSearch={efSearch:3d}: {search_time:6.2f} ms/query, recall={recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot HNSW results\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "times = [r['time'] for r in hnsw_results]\n",
    "recalls = [r['recall'] for r in hnsw_results]\n",
    "\n",
    "ax.plot(times, recalls, 'o-', label='HNSW', linewidth=2)\n",
    "ax.scatter([time_flat], [1.0], color='r', s=100, label='Flat (exact)', zorder=5)\n",
    "\n",
    "ax.set_xlabel('Latency (ms/query)')\n",
    "ax.set_ylabel('Recall@10')\n",
    "ax.set_title('HNSW: Latency vs Recall Trade-off')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Index Comparison\n",
    "\n",
    "Compare all three indexes side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimal parameters\n",
    "index_ivf.nprobe = 10\n",
    "index_hnsw.hnsw.efSearch = 64\n",
    "\n",
    "# Benchmark all\n",
    "indexes = [\n",
    "    ('Flat', index_flat),\n",
    "    ('IVF', index_ivf),\n",
    "    ('HNSW', index_hnsw)\n",
    "]\n",
    "\n",
    "print(f\"{'Index':<10} {'Latency (ms)':<15} {'Recall@10':<12} {'Speedup':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, idx in indexes:\n",
    "    # Search\n",
    "    start = time.time()\n",
    "    D, I = idx.search(queries, k)\n",
    "    latency = (time.time() - start) / len(queries) * 1000\n",
    "\n",
    "    # Recall\n",
    "    if name == 'Flat':\n",
    "        recall = 1.0\n",
    "        speedup = 1.0\n",
    "    else:\n",
    "        recall_sum = 0\n",
    "        for i in range(len(queries)):\n",
    "            true_set = set(I_flat[i])\n",
    "            pred_set = set(I[i])\n",
    "            recall_sum += len(true_set & pred_set) / k\n",
    "        recall = recall_sum / len(queries)\n",
    "        speedup = time_flat / latency\n",
    "\n",
    "    print(f\"{name:<10} {latency:<15.2f} {recall:<12.4f} {speedup:<10.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. When to Use Which Index?\n",
    "\n",
    "Decision guide based on dataset size and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_index(n_vectors, memory_limited=False, ultra_low_latency=False):\n",
    "    \"\"\"\n",
    "    Recommend FAISS index based on requirements.\n",
    "    \"\"\"\n",
    "    if n_vectors < 10_000:\n",
    "        return \"IndexFlatIP - Small dataset, use exact search\"\n",
    "\n",
    "    if n_vectors < 100_000:\n",
    "        if ultra_low_latency:\n",
    "            return \"IndexHNSWFlat - Fast and accurate\"\n",
    "        return \"IndexFlatIP or IndexHNSWFlat\"\n",
    "\n",
    "    if n_vectors < 1_000_000:\n",
    "        if memory_limited:\n",
    "            return \"IndexIVFFlat - Good balance\"\n",
    "        if ultra_low_latency:\n",
    "            return \"IndexHNSWFlat - Best latency\"\n",
    "        return \"IndexIVFFlat or IndexHNSWFlat\"\n",
    "\n",
    "    if n_vectors < 10_000_000:\n",
    "        if memory_limited:\n",
    "            return \"IndexIVFPQ - Compressed\"\n",
    "        return \"IndexIVFFlat with GPU\"\n",
    "\n",
    "    return \"IndexIVFPQ with sharding or use dedicated vector DB\"\n",
    "\n",
    "# Test recommendations\n",
    "test_cases = [\n",
    "    (5_000, False, False),\n",
    "    (50_000, False, True),\n",
    "    (500_000, False, False),\n",
    "    (500_000, True, False),\n",
    "    (5_000_000, False, False),\n",
    "]\n",
    "\n",
    "print(\"Index Recommendations:\\n\")\n",
    "for n, mem_limited, ultra_fast in test_cases:\n",
    "    rec = recommend_index(n, mem_limited, ultra_fast)\n",
    "    print(f\"{n:>10,} vectors, mem_limited={mem_limited}, ultra_fast={ultra_fast}\")\n",
    "    print(f\"  → {rec}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and Load Trained Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save IVF index (preserves training)\n",
    "faiss.write_index(index_ivf, \"ivf_index.faiss\")\n",
    "print(\"Saved IVF index\")\n",
    "\n",
    "# Save HNSW index\n",
    "faiss.write_index(index_hnsw, \"hnsw_index.faiss\")\n",
    "print(\"Saved HNSW index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and verify\n",
    "loaded_ivf = faiss.read_index(\"ivf_index.faiss\")\n",
    "print(f\"Loaded IVF: {loaded_ivf.ntotal:,} vectors\")\n",
    "print(f\"Is trained: {loaded_ivf.is_trained}\")\n",
    "print(f\"nlist: {loaded_ivf.nlist}\")\n",
    "\n",
    "# Set nprobe (not saved)\n",
    "loaded_ivf.nprobe = 10\n",
    "\n",
    "# Test search\n",
    "D, I = loaded_ivf.search(queries[:1], k=5)\n",
    "print(f\"\\n✓ Loaded IVF index works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Index Comparison\n",
    "\n",
    "| Index | Speed | Memory | Accuracy | Training | Best For |\n",
    "|-------|-------|--------|----------|----------|----------|\n",
    "| Flat | Slow | Low | 100% | No | <10K vectors |\n",
    "| IVF | Fast | Low | 95-99% | Yes | 100K-10M vectors |\n",
    "| HNSW | Very Fast | High | 95-99% | No | <10M, low latency |\n",
    "\n",
    "### Key Parameters\n",
    "\n",
    "**IVF:**\n",
    "- `nlist`: Number of clusters (√N to 4√N)\n",
    "- `nprobe`: Clusters to search (nlist/10 for 95%+ recall)\n",
    "\n",
    "**HNSW:**\n",
    "- `M`: Connections per layer (16-64)\n",
    "- `efConstruction`: Build quality (40-200)\n",
    "- `efSearch`: Search quality (16-256)\n",
    "\n",
    "**Next:** Learn optimization techniques and GPU acceleration!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
