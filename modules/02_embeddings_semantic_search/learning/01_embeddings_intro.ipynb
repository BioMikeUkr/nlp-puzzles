{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Text Embeddings\n",
    "\n",
    "This notebook covers the fundamentals of text embeddings.\n",
    "\n",
    "## Topics:\n",
    "1. What are embeddings?\n",
    "2. Using Sentence Transformers\n",
    "3. Similarity metrics\n",
    "4. Semantic search basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install sentence-transformers torch numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Model loaded: all-MiniLM-L6-v2\")\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What are Embeddings?\n",
    "\n",
    "Embeddings are dense numerical vectors that represent text in a way that captures semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode a single sentence\n",
    "text = \"How do I install Python?\"\n",
    "embedding = model.encode(text)\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Embedding shape: {embedding.shape}\")\n",
    "print(f\"First 10 values: {embedding[:10]}\")\n",
    "print(f\"Embedding norm: {np.linalg.norm(embedding):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode multiple sentences at once (more efficient)\n",
    "sentences = [\n",
    "    \"How do I install Python?\",\n",
    "    \"Python installation guide\",\n",
    "    \"Best restaurants in New York\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(f\"Shape: {embeddings.shape}\")  # (3, 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Similarity Metrics\n",
    "\n",
    "### Cosine Similarity\n",
    "Measures the angle between two vectors. Range: [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute pairwise similarities\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "for i, sent in enumerate(sentences):\n",
    "    print(f\"\\n{sent[:40]}...\")\n",
    "    for j, other in enumerate(sentences):\n",
    "        print(f\"  vs '{other[:30]}...': {similarities[i][j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual cosine similarity calculation\n",
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Compare first two sentences (both about Python)\n",
    "sim = cosine_sim(embeddings[0], embeddings[1])\n",
    "print(f\"Similarity between Python sentences: {sim:.4f}\")\n",
    "\n",
    "# Compare Python sentence with restaurant sentence\n",
    "sim = cosine_sim(embeddings[0], embeddings[2])\n",
    "print(f\"Similarity between Python and restaurant: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Product vs Cosine\n",
    "\n",
    "When vectors are normalized, dot product = cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize embeddings\n",
    "embeddings_normalized = model.encode(sentences, normalize_embeddings=True)\n",
    "\n",
    "# Now dot product = cosine similarity\n",
    "dot_product = np.dot(embeddings_normalized[0], embeddings_normalized[1])\n",
    "cosine = cosine_sim(embeddings[0], embeddings[1])\n",
    "\n",
    "print(f\"Dot product (normalized): {dot_product:.4f}\")\n",
    "print(f\"Cosine similarity: {cosine:.4f}\")\n",
    "print(f\"Same? {np.isclose(dot_product, cosine)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a corpus\n",
    "corpus = [\n",
    "    \"How to install Python on Windows\",\n",
    "    \"Python programming tutorial for beginners\",\n",
    "    \"Best Italian restaurants in Manhattan\",\n",
    "    \"Machine learning with Python\",\n",
    "    \"WiFi connection problems and solutions\",\n",
    "    \"Python virtual environments explained\",\n",
    "    \"Top pizza places in NYC\",\n",
    "    \"Setting up Python development environment\"\n",
    "]\n",
    "\n",
    "# Encode corpus\n",
    "corpus_embeddings = model.encode(corpus, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, corpus, corpus_embeddings, top_k=3):\n",
    "    \"\"\"Find most similar documents to query.\"\"\"\n",
    "    # Encode query\n",
    "    query_embedding = model.encode(query, normalize_embeddings=True)\n",
    "    \n",
    "    # Compute similarities (dot product since normalized)\n",
    "    similarities = np.dot(corpus_embeddings, query_embedding)\n",
    "    \n",
    "    # Get top-k indices\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    print(f\"Query: {query}\\n\")\n",
    "    for idx in top_indices:\n",
    "        print(f\"  Score: {similarities[idx]:.4f} | {corpus[idx]}\")\n",
    "\n",
    "# Test searches\n",
    "search(\"How do I set up Python?\", corpus, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different query\n",
    "search(\"good food places\", corpus, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query about networking\n",
    "search(\"internet not working\", corpus, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare embedding dimensions and speed\n",
    "import time\n",
    "\n",
    "models_to_compare = [\n",
    "    'all-MiniLM-L6-v2',      # 384 dims, fast\n",
    "    # 'all-mpnet-base-v2',   # 768 dims, slower but better\n",
    "]\n",
    "\n",
    "test_sentences = [\"This is a test sentence.\"] * 100\n",
    "\n",
    "for model_name in models_to_compare:\n",
    "    m = SentenceTransformer(model_name)\n",
    "    \n",
    "    start = time.time()\n",
    "    emb = m.encode(test_sentences)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Dimensions: {emb.shape[1]}\")\n",
    "    print(f\"  Time for 100 sentences: {elapsed:.3f}s\")\n",
    "    print(f\"  Sentences/sec: {100/elapsed:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Embeddings** convert text to vectors that capture meaning\n",
    "- **Cosine similarity** measures semantic similarity\n",
    "- **Normalized vectors** allow faster dot product computation\n",
    "- **Semantic search** finds similar documents by meaning, not keywords\n",
    "\n",
    "### Next:\n",
    "Try the tasks in `../tasks/` folder!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
