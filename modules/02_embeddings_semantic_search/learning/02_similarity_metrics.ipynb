{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Metrics Deep Dive\n",
    "\n",
    "This notebook explores different similarity metrics and when to use them.\n",
    "\n",
    "## Topics:\n",
    "1. Cosine similarity\n",
    "2. Dot product\n",
    "3. Euclidean distance\n",
    "4. Normalization effects\n",
    "5. Choosing the right metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple 2D vectors for visualization\n",
    "a = np.array([1, 2])\n",
    "b = np.array([2, 4])  # Same direction as a, different magnitude\n",
    "c = np.array([2, 1])  # Different direction\n",
    "\n",
    "print(\"Vectors:\")\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b} (same direction as a, 2x magnitude)\")\n",
    "print(f\"c = {c} (different direction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize vectors\n",
    "plt.figure(figsize=(8, 8))\n",
    "origin = np.array([0, 0])\n",
    "\n",
    "plt.quiver(*origin, *a, angles='xy', scale_units='xy', scale=1, color='r', label=f'a={a}')\n",
    "plt.quiver(*origin, *b, angles='xy', scale_units='xy', scale=1, color='g', label=f'b={b}')\n",
    "plt.quiver(*origin, *c, angles='xy', scale_units='xy', scale=1, color='b', label=f'c={c}')\n",
    "\n",
    "plt.xlim(-1, 5)\n",
    "plt.ylim(-1, 5)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Vector Visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all metrics\n",
    "def calculate_metrics(v1, v2):\n",
    "    # Dot product\n",
    "    dot = np.dot(v1, v2)\n",
    "    \n",
    "    # Cosine similarity\n",
    "    cosine = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    \n",
    "    # Euclidean distance\n",
    "    euclidean = np.linalg.norm(v1 - v2)\n",
    "    \n",
    "    return {\n",
    "        'dot_product': dot,\n",
    "        'cosine_similarity': cosine,\n",
    "        'euclidean_distance': euclidean\n",
    "    }\n",
    "\n",
    "print(\"a vs b (same direction):\")\n",
    "for k, v in calculate_metrics(a, b).items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\na vs c (different direction):\")\n",
    "for k, v in calculate_metrics(a, c).items():\n",
    "    print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Effect of Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize vectors (L2 normalization)\n",
    "def normalize(v):\n",
    "    return v / np.linalg.norm(v)\n",
    "\n",
    "a_norm = normalize(a)\n",
    "b_norm = normalize(b)\n",
    "c_norm = normalize(c)\n",
    "\n",
    "print(\"Normalized vectors:\")\n",
    "print(f\"a_norm = {a_norm}, norm = {np.linalg.norm(a_norm):.4f}\")\n",
    "print(f\"b_norm = {b_norm}, norm = {np.linalg.norm(b_norm):.4f}\")\n",
    "print(f\"c_norm = {c_norm}, norm = {np.linalg.norm(c_norm):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After normalization: dot product = cosine similarity\n",
    "print(\"a_norm vs b_norm (were same direction):\")\n",
    "metrics = calculate_metrics(a_norm, b_norm)\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "print(f\"\\nDot product == Cosine? {np.isclose(metrics['dot_product'], metrics['cosine_similarity'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Real Text Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"How to install Python\",\n",
    "    \"Python installation guide\",\n",
    "    \"Best restaurants in NYC\",\n",
    "    \"How to install Python on Windows step by step\",  # Longer version\n",
    "]\n",
    "\n",
    "# Get embeddings (not normalized)\n",
    "embeddings = model.encode(texts, normalize_embeddings=False)\n",
    "\n",
    "# Get normalized embeddings\n",
    "embeddings_norm = model.encode(texts, normalize_embeddings=True)\n",
    "\n",
    "print(\"Embedding norms (not normalized):\")\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"  {text[:40]}: {np.linalg.norm(embeddings[i]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare similarity matrices\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "cos_sim = cosine_similarity(embeddings)\n",
    "print(np.round(cos_sim, 3))\n",
    "\n",
    "print(\"\\nDot Product Matrix (normalized embeddings):\")\n",
    "dot_sim = np.dot(embeddings_norm, embeddings_norm.T)\n",
    "print(np.round(dot_sim, 3))\n",
    "\n",
    "print(\"\\nAre they equal?\")\n",
    "print(np.allclose(cos_sim, dot_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. When to Use Which Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance for clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster_texts = [\n",
    "    \"Python programming\",\n",
    "    \"Python tutorial\",\n",
    "    \"Learn Python\",\n",
    "    \"Italian food\",\n",
    "    \"Pizza restaurant\",\n",
    "    \"Best pasta\",\n",
    "]\n",
    "\n",
    "cluster_embeddings = model.encode(cluster_texts)\n",
    "\n",
    "# K-means uses Euclidean distance internally\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "labels = kmeans.fit_predict(cluster_embeddings)\n",
    "\n",
    "print(\"Clustering results (Euclidean-based):\")\n",
    "for text, label in zip(cluster_texts, labels):\n",
    "    print(f\"  Cluster {label}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "print(\"\"\"\n",
    "METRIC COMPARISON:\n",
    "\n",
    "| Metric              | Range      | When to use                    |\n",
    "|---------------------|------------|--------------------------------|\n",
    "| Cosine Similarity   | [-1, 1]    | Semantic similarity, search    |\n",
    "| Dot Product         | (-inf,inf) | Normalized vectors (faster)    |\n",
    "| Euclidean Distance  | [0, inf)   | Clustering, when magnitude     |\n",
    "|                     |            | matters                        |\n",
    "\n",
    "For most NLP tasks: Use COSINE SIMILARITY (or dot product with normalized vectors)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Generate random embeddings\n",
    "n = 10000\n",
    "dim = 384\n",
    "corpus = np.random.randn(n, dim)\n",
    "query = np.random.randn(dim)\n",
    "\n",
    "# Normalize\n",
    "corpus_norm = corpus / np.linalg.norm(corpus, axis=1, keepdims=True)\n",
    "query_norm = query / np.linalg.norm(query)\n",
    "\n",
    "# Time comparison\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    sims = cosine_similarity([query], corpus)[0]\n",
    "cosine_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    sims = np.dot(corpus_norm, query_norm)\n",
    "dot_time = time.time() - start\n",
    "\n",
    "print(f\"Time for 100 searches over {n} vectors:\")\n",
    "print(f\"  Cosine similarity: {cosine_time:.3f}s\")\n",
    "print(f\"  Dot product (norm): {dot_time:.3f}s\")\n",
    "print(f\"  Speedup: {cosine_time/dot_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Cosine similarity** is best for semantic similarity (direction-based)\n",
    "- **Normalize embeddings** to use faster dot product\n",
    "- **Euclidean distance** is useful for clustering\n",
    "- **Pre-normalize** corpus embeddings for efficient search\n",
    "\n",
    "### Next:\n",
    "Try the tasks in `../tasks/` folder!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
