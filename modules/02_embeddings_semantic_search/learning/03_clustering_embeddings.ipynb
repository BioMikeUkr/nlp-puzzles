{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Clustering Text Embeddings\n",
    "\n",
    "This notebook covers clustering techniques for text embeddings.\n",
    "\n",
    "## Topics:\n",
    "1. K-Means clustering\n",
    "2. Choosing the number of clusters (Elbow, Silhouette)\n",
    "3. Hierarchical clustering\n",
    "4. DBSCAN for density-based clustering\n",
    "5. Visualizing clusters with t-SNE/UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Sample Data\n",
    "\n",
    "Create a corpus with distinct topics for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents from different categories\n",
    "documents = [\n",
    "    # Software Installation (cluster 0)\n",
    "    \"How to install Python on Windows\",\n",
    "    \"Python installation guide for beginners\",\n",
    "    \"Setting up Python development environment\",\n",
    "    \"Installing Python packages with pip\",\n",
    "    \"Python virtual environment setup\",\n",
    "    \n",
    "    # Network Issues (cluster 1)\n",
    "    \"WiFi connection keeps dropping\",\n",
    "    \"Cannot connect to the internet\",\n",
    "    \"Network troubleshooting steps\",\n",
    "    \"Slow internet connection problems\",\n",
    "    \"VPN connection issues\",\n",
    "    \n",
    "    # Hardware (cluster 2)\n",
    "    \"Laptop screen is flickering\",\n",
    "    \"Computer won't turn on\",\n",
    "    \"Keyboard keys not working\",\n",
    "    \"Mouse cursor freezing\",\n",
    "    \"Laptop battery draining fast\",\n",
    "    \n",
    "    # Email (cluster 3)\n",
    "    \"Cannot send emails from Outlook\",\n",
    "    \"Email attachment size limit\",\n",
    "    \"How to set up email signature\",\n",
    "    \"Emails going to spam folder\",\n",
    "    \"Email synchronization problems\",\n",
    "]\n",
    "\n",
    "# True labels for evaluation\n",
    "true_labels = [0]*5 + [1]*5 + [2]*5 + [3]*5\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = model.encode(documents)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 1. K-Means Clustering\n",
    "\n",
    "K-Means partitions data into K clusters by minimizing within-cluster variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic K-Means\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "print(\"K-Means Clustering Results:\")\n",
    "for cluster_id in range(4):\n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    for i, doc in enumerate(documents):\n",
    "        if labels[i] == cluster_id:\n",
    "            print(f\"  - {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster centroids - can be used to find representative documents\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(f\"Centroid shape: {centroids.shape}\")\n",
    "\n",
    "# Find document closest to each centroid\n",
    "print(\"\\nRepresentative documents (closest to centroid):\")\n",
    "for cluster_id in range(4):\n",
    "    # Get documents in this cluster\n",
    "    cluster_mask = labels == cluster_id\n",
    "    cluster_embeddings = embeddings[cluster_mask]\n",
    "    cluster_docs = [doc for i, doc in enumerate(documents) if labels[i] == cluster_id]\n",
    "    \n",
    "    # Find closest to centroid\n",
    "    distances = np.linalg.norm(cluster_embeddings - centroids[cluster_id], axis=1)\n",
    "    closest_idx = np.argmin(distances)\n",
    "    print(f\"Cluster {cluster_id}: {cluster_docs[closest_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 2. Choosing the Number of Clusters\n",
    "\n",
    "### Elbow Method\n",
    "Plot inertia (within-cluster sum of squares) vs number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method\n",
    "inertias = []\n",
    "K_range = range(2, 10)\n",
    "\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(embeddings)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(K_range, inertias, 'bo-')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method')\n",
    "plt.axvline(x=4, color='r', linestyle='--', label='Elbow at K=4')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "### Silhouette Score\n",
    "Measures how similar an object is to its own cluster vs other clusters. Range: [-1, 1], higher is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette scores\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(embeddings)\n",
    "    score = silhouette_score(embeddings, labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(f\"K={k}: Silhouette Score = {score:.4f}\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(K_range, silhouette_scores, 'go-')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Method')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_k = list(K_range)[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nBest K by Silhouette: {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 3. Hierarchical Clustering\n",
    "\n",
    "Builds a hierarchy of clusters. Good for understanding relationships between clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Create linkage matrix\n",
    "linkage_matrix = linkage(embeddings, method='ward')\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(\n",
    "    linkage_matrix,\n",
    "    labels=[doc[:25] + '...' for doc in documents],\n",
    "    leaf_rotation=90,\n",
    "    leaf_font_size=8\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Documents')\n",
    "plt.ylabel('Distance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomerative clustering with sklearn\n",
    "agg = AgglomerativeClustering(n_clusters=4, linkage='ward')\n",
    "agg_labels = agg.fit_predict(embeddings)\n",
    "\n",
    "print(\"Agglomerative Clustering Results:\")\n",
    "for cluster_id in range(4):\n",
    "    print(f\"\\nCluster {cluster_id}:\")\n",
    "    for i, doc in enumerate(documents):\n",
    "        if agg_labels[i] == cluster_id:\n",
    "            print(f\"  - {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 4. DBSCAN - Density-Based Clustering\n",
    "\n",
    "Finds clusters of arbitrary shape. Good for detecting outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "# eps: maximum distance between two samples in same neighborhood\n",
    "# min_samples: minimum points to form a dense region\n",
    "\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=2, metric='cosine')\n",
    "db_labels = dbscan.fit_predict(embeddings)\n",
    "\n",
    "n_clusters = len(set(db_labels)) - (1 if -1 in db_labels else 0)\n",
    "n_noise = list(db_labels).count(-1)\n",
    "\n",
    "print(f\"DBSCAN found {n_clusters} clusters and {n_noise} noise points\")\n",
    "\n",
    "for cluster_id in sorted(set(db_labels)):\n",
    "    label = \"Noise\" if cluster_id == -1 else f\"Cluster {cluster_id}\"\n",
    "    print(f\"\\n{label}:\")\n",
    "    for i, doc in enumerate(documents):\n",
    "        if db_labels[i] == cluster_id:\n",
    "            print(f\"  - {doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding optimal eps using k-distance plot\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Calculate distances to k nearest neighbors\n",
    "k = 3\n",
    "nn = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "nn.fit(embeddings)\n",
    "distances, _ = nn.kneighbors(embeddings)\n",
    "\n",
    "# Sort distances to k-th neighbor\n",
    "k_distances = np.sort(distances[:, k-1])\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(k_distances)\n",
    "plt.xlabel('Points sorted by distance')\n",
    "plt.ylabel(f'{k}-NN distance')\n",
    "plt.title('K-Distance Plot (for choosing eps)')\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label='Potential eps')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 5. Visualizing Clusters with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D with t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Plot with K-Means labels\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "km_labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# K-Means clusters\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                      c=km_labels, cmap='viridis', s=100)\n",
    "plt.colorbar(scatter)\n",
    "plt.title('K-Means Clusters (t-SNE)')\n",
    "\n",
    "# Add labels\n",
    "for i, doc in enumerate(documents):\n",
    "    plt.annotate(doc[:15] + '...', \n",
    "                 (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
    "                 fontsize=6, alpha=0.7)\n",
    "\n",
    "# True labels\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                      c=true_labels, cmap='viridis', s=100)\n",
    "plt.colorbar(scatter)\n",
    "plt.title('True Labels (t-SNE)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 6. Cluster Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "# Compare predicted vs true labels\n",
    "km_labels = KMeans(n_clusters=4, random_state=42, n_init=10).fit_predict(embeddings)\n",
    "\n",
    "# Adjusted Rand Index: measures similarity between clusterings\n",
    "# Range: [-1, 1], 1 = perfect match, 0 = random\n",
    "ari = adjusted_rand_score(true_labels, km_labels)\n",
    "\n",
    "# Normalized Mutual Information: measures shared information\n",
    "# Range: [0, 1], 1 = perfect match\n",
    "nmi = normalized_mutual_info_score(true_labels, km_labels)\n",
    "\n",
    "# Silhouette (doesn't need true labels)\n",
    "sil = silhouette_score(embeddings, km_labels)\n",
    "\n",
    "print(\"Cluster Quality Metrics:\")\n",
    "print(f\"  Adjusted Rand Index: {ari:.4f}\")\n",
    "print(f\"  Normalized Mutual Info: {nmi:.4f}\")\n",
    "print(f\"  Silhouette Score: {sil:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 7. Practical Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip 1: Normalize embeddings before clustering\n",
    "embeddings_norm = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# Tip 2: Use cosine distance for K-Means (via normalization)\n",
    "# After normalization, Euclidean distance âˆ cosine distance\n",
    "km_norm = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "labels_norm = km_norm.fit_predict(embeddings_norm)\n",
    "\n",
    "print(\"Silhouette with normalized embeddings:\", \n",
    "      silhouette_score(embeddings_norm, labels_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip 3: Get cluster labels for new documents\n",
    "def assign_cluster(text, kmeans_model, model):\n",
    "    \"\"\"Assign a new document to existing clusters.\"\"\"\n",
    "    embedding = model.encode([text])\n",
    "    embedding_norm = embedding / np.linalg.norm(embedding)\n",
    "    return kmeans_model.predict(embedding_norm)[0]\n",
    "\n",
    "new_doc = \"How to upgrade Python version\"\n",
    "cluster = assign_cluster(new_doc, km_norm, model)\n",
    "print(f\"'{new_doc}' -> Cluster {cluster}\")\n",
    "\n",
    "new_doc = \"Printer not printing\"\n",
    "cluster = assign_cluster(new_doc, km_norm, model)\n",
    "print(f\"'{new_doc}' -> Cluster {cluster}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Method | Pros | Cons | Best For |\n",
    "|--------|------|------|----------|\n",
    "| K-Means | Fast, scalable | Need to choose K, spherical clusters | Large datasets |\n",
    "| Hierarchical | Visual dendrograms, no K needed | Slow for large data | Understanding structure |\n",
    "| DBSCAN | Finds outliers, arbitrary shapes | Sensitive to eps/min_samples | Noisy data |\n",
    "\n",
    "**Key steps:**\n",
    "1. Normalize embeddings for cosine-based clustering\n",
    "2. Use Elbow + Silhouette to choose K\n",
    "3. Visualize with t-SNE to validate\n",
    "4. Use Silhouette/ARI/NMI to evaluate quality\n",
    "\n",
    "### Next:\n",
    "Try the clustering task in `../tasks/` folder!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
