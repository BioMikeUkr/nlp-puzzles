{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Task 2: Build a File Upload and Processing API\n",
    "\n",
    "## Scenario\n",
    "Build a FastAPI service that handles file uploads with background processing:\n",
    "1. Accept file uploads with validation\n",
    "2. Process files in background tasks\n",
    "3. Track processing status\n",
    "4. Use async file operations for efficiency\n",
    "\n",
    "## Your Tasks:\n",
    "1. **File upload endpoint**: Accept and validate files\n",
    "2. **Background processing**: Process files asynchronously\n",
    "3. **Status tracking**: Check processing status\n",
    "4. **Results retrieval**: Get processed results\n",
    "5. **Error handling**: Handle file errors gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup (provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks, status\n",
    "from fastapi.testclient import TestClient\n",
    "from pydantic import BaseModel, Field\n",
    "import aiofiles\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### Create temporary directory for file storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "# Create temp directory for this session\n",
    "TEMP_DIR = Path(tempfile.mkdtemp())\n",
    "UPLOAD_DIR = TEMP_DIR / \"uploads\"\n",
    "RESULTS_DIR = TEMP_DIR / \"results\"\n",
    "\n",
    "UPLOAD_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Upload directory: {UPLOAD_DIR}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Setup Job Tracking and App\n",
    "\n",
    "Create:\n",
    "- Global dictionary `jobs` to track processing jobs\n",
    "  - Structure: `{job_id: {\"status\": str, \"filename\": str, \"result\": dict}}`\n",
    "- `lifespan` context manager for cleanup\n",
    "- FastAPI app with the lifespan\n",
    "\n",
    "Job statuses: \"pending\", \"processing\", \"completed\", \"failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Create jobs dict\n",
    "# 2. Create lifespan with cleanup\n",
    "# 3. Create FastAPI app\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Do not modify\n",
    "assert 'jobs' in dir(), \"jobs dict not found\"\n",
    "assert 'lifespan' in dir(), \"lifespan function not found\"\n",
    "assert 'app' in dir(), \"app not found\"\n",
    "assert isinstance(jobs, dict), \"jobs should be a dict\"\n",
    "\n",
    "client = TestClient(app)\n",
    "\n",
    "print(\"✓ Task 1 PASSED!\")\n",
    "print(\"  Job tracking and app initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Define Pydantic Models\n",
    "\n",
    "Create:\n",
    "\n",
    "1. **`UploadResponse`**:\n",
    "   - `job_id`: str\n",
    "   - `filename`: str\n",
    "   - `status`: str\n",
    "   - `message`: str\n",
    "\n",
    "2. **`JobStatus`**:\n",
    "   - `job_id`: str\n",
    "   - `status`: str\n",
    "   - `filename`: str\n",
    "   - `result`: Optional[Dict] = None\n",
    "\n",
    "3. **`ProcessingResult`**:\n",
    "   - `line_count`: int\n",
    "   - `word_count`: int\n",
    "   - `char_count`: int\n",
    "   - `processing_time`: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Define all three Pydantic models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Do not modify\n",
    "assert 'UploadResponse' in dir(), \"UploadResponse not found\"\n",
    "assert 'JobStatus' in dir(), \"JobStatus not found\"\n",
    "assert 'ProcessingResult' in dir(), \"ProcessingResult not found\"\n",
    "\n",
    "# Test models\n",
    "upload_resp = UploadResponse(\n",
    "    job_id=\"test-123\",\n",
    "    filename=\"test.txt\",\n",
    "    status=\"pending\",\n",
    "    message=\"File uploaded\"\n",
    ")\n",
    "assert upload_resp.job_id == \"test-123\"\n",
    "\n",
    "job_status = JobStatus(\n",
    "    job_id=\"test-123\",\n",
    "    status=\"completed\",\n",
    "    filename=\"test.txt\",\n",
    "    result={\"lines\": 10}\n",
    ")\n",
    "assert job_status.result is not None\n",
    "\n",
    "result = ProcessingResult(\n",
    "    line_count=10,\n",
    "    word_count=50,\n",
    "    char_count=300,\n",
    "    processing_time=0.5\n",
    ")\n",
    "assert result.line_count == 10\n",
    "\n",
    "print(\"✓ Task 2 PASSED!\")\n",
    "print(\"  All Pydantic models defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Implement Background Processing Function\n",
    "\n",
    "Create an async function `process_file(job_id: str, file_path: Path)` that:\n",
    "1. Updates job status to \"processing\"\n",
    "2. Reads file asynchronously with aiofiles\n",
    "3. Counts lines, words, and characters\n",
    "4. Saves result to jobs dict\n",
    "5. Updates status to \"completed\" or \"failed\"\n",
    "\n",
    "Use try-except to handle errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Implement async process_file function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "# TEST - Do not modify\nassert 'process_file' in dir(), \"process_file function not found\"\n\n# Create test file\ntest_file = UPLOAD_DIR / \"test_processing.txt\"\ntest_file.write_text(\"Hello world\\nThis is a test\\nThree lines total\")\n\n# Test processing\ntest_job_id = \"test-job-123\"\njobs[test_job_id] = {\"status\": \"pending\", \"filename\": \"test_processing.txt\"}\n\n# Run async function (use await in Jupyter since event loop is already running)\nawait process_file(test_job_id, test_file)\n\n# Check results\nassert jobs[test_job_id]['status'] == 'completed', f\"Expected completed, got {jobs[test_job_id]['status']}\"\nassert 'result' in jobs[test_job_id], \"Result not found in job\"\nresult = jobs[test_job_id]['result']\nassert result['line_count'] == 3, f\"Expected 3 lines, got {result['line_count']}\"\nassert result['word_count'] > 0, \"Word count should be > 0\"\nassert result['char_count'] > 0, \"Char count should be > 0\"\n\nprint(\"✓ Task 3 PASSED!\")\nprint(f\"  Processing result: {result}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4: Implement File Upload Endpoint\n",
    "\n",
    "Create POST endpoint `/upload` that:\n",
    "- Accepts `UploadFile`\n",
    "- Validates file type (only .txt files, max 10MB)\n",
    "- Saves file to UPLOAD_DIR\n",
    "- Creates job entry\n",
    "- Schedules background processing\n",
    "- Returns `UploadResponse`\n",
    "\n",
    "Use `BackgroundTasks` to schedule processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Implement /upload endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Do not modify\n",
    "from io import BytesIO\n",
    "\n",
    "client = TestClient(app)\n",
    "\n",
    "# Create test file content\n",
    "test_content = b\"Line 1\\nLine 2\\nLine 3\"\n",
    "test_file = (\"test.txt\", BytesIO(test_content), \"text/plain\")\n",
    "\n",
    "# Upload file\n",
    "response = client.post(\n",
    "    \"/upload\",\n",
    "    files={\"file\": test_file}\n",
    ")\n",
    "\n",
    "assert response.status_code == 200, f\"Expected 200, got {response.status_code}\"\n",
    "data = response.json()\n",
    "assert 'job_id' in data, \"Response missing job_id\"\n",
    "assert 'filename' in data, \"Response missing filename\"\n",
    "assert 'status' in data, \"Response missing status\"\n",
    "assert data['status'] == 'pending', f\"Expected pending, got {data['status']}\"\n",
    "\n",
    "job_id = data['job_id']\n",
    "assert job_id in jobs, \"Job not found in jobs dict\"\n",
    "\n",
    "# Test invalid file type\n",
    "invalid_file = (\"test.exe\", BytesIO(b\"fake exe\"), \"application/x-msdownload\")\n",
    "response = client.post(\n",
    "    \"/upload\",\n",
    "    files={\"file\": invalid_file}\n",
    ")\n",
    "assert response.status_code == 400, \"Invalid file type should return 400\"\n",
    "\n",
    "# Wait a bit for background task\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"✓ Task 4 PASSED!\")\n",
    "print(f\"  File uploaded with job_id: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 5: Implement Status and Results Endpoints\n",
    "\n",
    "Create:\n",
    "\n",
    "1. **GET `/jobs/{job_id}`**: Returns `JobStatus`\n",
    "   - 404 if job not found\n",
    "\n",
    "2. **GET `/jobs`**: Returns list of all jobs\n",
    "\n",
    "3. **DELETE `/jobs/{job_id}`**: Delete job and associated files\n",
    "   - 404 if job not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Implement status and management endpoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Do not modify\n",
    "client = TestClient(app)\n",
    "\n",
    "# First upload a file\n",
    "test_content = b\"Test line 1\\nTest line 2\"\n",
    "response = client.post(\n",
    "    \"/upload\",\n",
    "    files={\"file\": (\"status_test.txt\", BytesIO(test_content), \"text/plain\")}\n",
    ")\n",
    "job_id = response.json()['job_id']\n",
    "\n",
    "# Wait for processing\n",
    "time.sleep(1)\n",
    "\n",
    "# Test get specific job\n",
    "response = client.get(f\"/jobs/{job_id}\")\n",
    "assert response.status_code == 200, f\"Expected 200, got {response.status_code}\"\n",
    "data = response.json()\n",
    "assert data['job_id'] == job_id\n",
    "assert data['status'] in ['pending', 'processing', 'completed'], f\"Unexpected status: {data['status']}\"\n",
    "\n",
    "# Test get all jobs\n",
    "response = client.get(\"/jobs\")\n",
    "assert response.status_code == 200\n",
    "jobs_list = response.json()\n",
    "assert isinstance(jobs_list, list), \"Expected list of jobs\"\n",
    "assert len(jobs_list) > 0, \"Should have at least one job\"\n",
    "\n",
    "# Test delete job\n",
    "response = client.delete(f\"/jobs/{job_id}\")\n",
    "assert response.status_code == 200\n",
    "\n",
    "# Verify job deleted\n",
    "response = client.get(f\"/jobs/{job_id}\")\n",
    "assert response.status_code == 404, \"Deleted job should return 404\"\n",
    "\n",
    "# Test non-existent job\n",
    "response = client.get(\"/jobs/fake-job-id\")\n",
    "assert response.status_code == 404, \"Non-existent job should return 404\"\n",
    "\n",
    "print(\"✓ Task 5 PASSED!\")\n",
    "print(\"  Status and management endpoints working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Test Complete Upload Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real test file\n",
    "with open('../fixtures/input/test_file.txt', 'rb') as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "print(\"=== Complete File Upload Flow ===\")\n",
    "print()\n",
    "\n",
    "# 1. Upload file\n",
    "response = client.post(\n",
    "    \"/upload\",\n",
    "    files={\"file\": (\"test_file.txt\", BytesIO(file_content), \"text/plain\")}\n",
    ")\n",
    "print(\"1. File Upload:\")\n",
    "upload_data = response.json()\n",
    "print(f\"   Job ID: {upload_data['job_id']}\")\n",
    "print(f\"   Status: {upload_data['status']}\")\n",
    "print()\n",
    "\n",
    "job_id = upload_data['job_id']\n",
    "\n",
    "# 2. Check status immediately\n",
    "response = client.get(f\"/jobs/{job_id}\")\n",
    "print(\"2. Initial Status:\")\n",
    "status_data = response.json()\n",
    "print(f\"   Status: {status_data['status']}\")\n",
    "print()\n",
    "\n",
    "# 3. Wait for processing\n",
    "print(\"3. Waiting for processing...\")\n",
    "time.sleep(2)\n",
    "\n",
    "# 4. Check final status\n",
    "response = client.get(f\"/jobs/{job_id}\")\n",
    "print(\"\\n4. Final Status:\")\n",
    "final_data = response.json()\n",
    "print(f\"   Status: {final_data['status']}\")\n",
    "if final_data.get('result'):\n",
    "    print(\"   Results:\")\n",
    "    for key, value in final_data['result'].items():\n",
    "        print(f\"     - {key}: {value}\")\n",
    "print()\n",
    "\n",
    "# 5. List all jobs\n",
    "response = client.get(\"/jobs\")\n",
    "all_jobs = response.json()\n",
    "print(f\"5. Total Jobs: {len(all_jobs)}\")\n",
    "print()\n",
    "\n",
    "print(\"✓ Complete flow test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup temp directory\n",
    "shutil.rmtree(TEMP_DIR)\n",
    "print(f\"Cleaned up: {TEMP_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "## Expected Results\n",
    "\n",
    "After completing all tasks:\n",
    "- **Task 1**: Job tracking system initialized\n",
    "- **Task 2**: Pydantic models for upload/status\n",
    "- **Task 3**: Background processing function\n",
    "- **Task 4**: File upload with validation\n",
    "- **Task 5**: Status checking and job management\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **File uploads**: Use `UploadFile` for efficient streaming\n",
    "2. **Background tasks**: Process files without blocking requests\n",
    "3. **Async file I/O**: Use `aiofiles` for non-blocking file operations\n",
    "4. **Job tracking**: Maintain state across requests\n",
    "5. **Validation**: Check file types and sizes before processing\n",
    "6. **Error handling**: Graceful failures with proper status codes\n",
    "\n",
    "## Common Pitfalls\n",
    "- Forgetting to handle file encoding errors\n",
    "- Not cleaning up uploaded files\n",
    "- Blocking operations in async context\n",
    "- Not validating file size before reading\n",
    "- Race conditions in job status updates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}