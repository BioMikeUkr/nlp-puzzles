{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Task 1: Build a Text Classification API\n",
    "\n",
    "## Scenario\n",
    "Build a production-ready FastAPI service for sentiment classification that:\n",
    "1. Loads a model efficiently using lifespan context\n",
    "2. Validates input/output with Pydantic models\n",
    "3. Provides single and batch classification endpoints\n",
    "4. Includes proper error handling\n",
    "\n",
    "## Your Tasks:\n",
    "1. **Setup lifespan**: Create FastAPI app with model loading in lifespan\n",
    "2. **Define Pydantic models**: Request/response validation\n",
    "3. **Single classification**: Endpoint for one text at a time\n",
    "4. **Batch classification**: Endpoint for multiple texts\n",
    "5. **Error handling**: Handle edge cases gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup (provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from contextlib import asynccontextmanager\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from fastapi import FastAPI, HTTPException, status\n",
    "from fastapi.testclient import TestClient\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### Helper: Train a simple classifier\n",
    "\n",
    "We'll train a simple sentiment classifier for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "with open('../fixtures/input/sample_texts.json') as f:\n",
    "    sample_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(sample_data)} samples\")\n",
    "print(f\"\\nSample: {sample_data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple classifier (for demo purposes)\n",
    "def train_simple_classifier():\n",
    "    \"\"\"Train a simple sentiment classifier.\"\"\"\n",
    "    texts = [item['text'] for item in sample_data]\n",
    "    labels = [item['expected_label'] for item in sample_data]\n",
    "    \n",
    "    # Create embeddings\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(texts)\n",
    "    \n",
    "    # Train classifier\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(embeddings, labels)\n",
    "    \n",
    "    return model, clf\n",
    "\n",
    "# We'll use this in our API\n",
    "print(\"Classifier training function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Create Lifespan Context and App\n",
    "\n",
    "Create:\n",
    "- Global dictionary `ml_models` to store models\n",
    "- `lifespan` async context manager that:\n",
    "  - Loads models on startup\n",
    "  - Stores them in `ml_models[\"encoder\"]` and `ml_models[\"classifier\"]`\n",
    "  - Cleans up on shutdown\n",
    "- FastAPI app with the lifespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Create ml_models dict\n",
    "# 2. Create lifespan async context manager\n",
    "# 3. Create FastAPI app with lifespan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# TEST - Do not modify\nassert 'ml_models' in dir(), \"ml_models dict not found\"\nassert 'lifespan' in dir(), \"lifespan function not found\"\nassert 'app' in dir(), \"app not found\"\n\n# Test that models load (context manager triggers lifespan startup)\nwith TestClient(app) as client:\n    assert 'encoder' in ml_models, \"encoder not loaded in ml_models\"\n    assert 'classifier' in ml_models, \"classifier not loaded in ml_models\"\n    print(\"✓ Task 1 PASSED!\")\n    print(f\"  Models loaded: {list(ml_models.keys())}\")\n\n# Re-load models for subsequent cells (lifespan cleanup clears them)\nencoder, classifier = train_simple_classifier()\nml_models[\"encoder\"] = encoder\nml_models[\"classifier\"] = classifier"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Define Pydantic Models\n",
    "\n",
    "Create Pydantic models:\n",
    "\n",
    "1. **`TextInput`**: \n",
    "   - `text`: str (min length 1, max length 5000)\n",
    "\n",
    "2. **`ClassificationResult`**:\n",
    "   - `text`: str\n",
    "   - `label`: str\n",
    "   - `confidence`: float (between 0 and 1)\n",
    "\n",
    "3. **`BatchTextInput`**:\n",
    "   - `texts`: List[str] (min 1 item, max 100 items)\n",
    "\n",
    "4. **`BatchClassificationResult`**:\n",
    "   - `results`: List[ClassificationResult]\n",
    "   - `count`: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Define all four Pydantic models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - Do not modify\n",
    "assert 'TextInput' in dir(), \"TextInput not found\"\n",
    "assert 'ClassificationResult' in dir(), \"ClassificationResult not found\"\n",
    "assert 'BatchTextInput' in dir(), \"BatchTextInput not found\"\n",
    "assert 'BatchClassificationResult' in dir(), \"BatchClassificationResult not found\"\n",
    "\n",
    "# Test validation\n",
    "valid_input = TextInput(text=\"This is a test\")\n",
    "assert valid_input.text == \"This is a test\"\n",
    "\n",
    "try:\n",
    "    TextInput(text=\"\")  # Should fail\n",
    "    assert False, \"Empty text should be rejected\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    TextInput(text=\"a\" * 6000)  # Should fail\n",
    "    assert False, \"Text too long should be rejected\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "result = ClassificationResult(text=\"test\", label=\"positive\", confidence=0.95)\n",
    "assert 0 <= result.confidence <= 1\n",
    "\n",
    "batch_input = BatchTextInput(texts=[\"text1\", \"text2\"])\n",
    "assert len(batch_input.texts) == 2\n",
    "\n",
    "print(\"✓ Task 2 PASSED!\")\n",
    "print(\"  All Pydantic models defined with proper validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Implement Single Classification Endpoint\n",
    "\n",
    "Create a POST endpoint `/classify` that:\n",
    "- Takes `TextInput`\n",
    "- Returns `ClassificationResult`\n",
    "- Uses the loaded models from `ml_models`\n",
    "- Handles errors with appropriate HTTP status codes\n",
    "\n",
    "Implementation steps:\n",
    "1. Encode the input text\n",
    "2. Predict with classifier\n",
    "3. Get probability for confidence\n",
    "4. Return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Implement the /classify endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "# TEST - Do not modify\nwith TestClient(app) as client:\n    # Test positive sentiment\n    response = client.post(\n        \"/classify\",\n        json={\"text\": \"This is amazing! I love it!\"}\n    )\n    assert response.status_code == 200, f\"Expected 200, got {response.status_code}\"\n    data = response.json()\n    assert 'label' in data, \"Response missing 'label'\"\n    assert 'confidence' in data, \"Response missing 'confidence'\"\n    assert 'text' in data, \"Response missing 'text'\"\n    assert 0 <= data['confidence'] <= 1, \"Confidence should be between 0 and 1\"\n    assert data['label'] == 'positive', f\"Expected 'positive', got {data['label']}\"\n\n    # Test negative sentiment\n    response = client.post(\n        \"/classify\",\n        json={\"text\": \"This is terrible and awful!\"}\n    )\n    assert response.status_code == 200\n    data = response.json()\n    assert data['label'] == 'negative', f\"Expected 'negative', got {data['label']}\"\n\n    # Test validation error\n    response = client.post(\n        \"/classify\",\n        json={\"text\": \"\"}  # Empty text\n    )\n    assert response.status_code == 422, \"Empty text should return 422\"\n\nprint(\"✓ Task 3 PASSED!\")\nprint(\"  /classify endpoint working correctly\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4: Implement Batch Classification Endpoint\n",
    "\n",
    "Create a POST endpoint `/classify/batch` that:\n",
    "- Takes `BatchTextInput`\n",
    "- Returns `BatchClassificationResult`\n",
    "- Processes all texts efficiently (batch encoding)\n",
    "- Handles errors gracefully\n",
    "\n",
    "Implementation steps:\n",
    "1. Encode all texts in batch\n",
    "2. Predict for all texts\n",
    "3. Get probabilities\n",
    "4. Build list of results\n",
    "5. Return with count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Implement the /classify/batch endpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": "# TEST - Do not modify\nwith TestClient(app) as client:\n    # Test batch classification\n    response = client.post(\n        \"/classify/batch\",\n        json={\n            \"texts\": [\n                \"This is amazing!\",\n                \"Terrible quality. Complete waste of money.\",\n                \"The package arrived today.\"\n            ]\n        }\n    )\n    assert response.status_code == 200, f\"Expected 200, got {response.status_code}\"\n    data = response.json()\n    assert 'results' in data, \"Response missing 'results'\"\n    assert 'count' in data, \"Response missing 'count'\"\n    assert data['count'] == 3, f\"Expected count=3, got {data['count']}\"\n    assert len(data['results']) == 3, f\"Expected 3 results, got {len(data['results'])}\"\n\n    # Check first result is positive\n    assert data['results'][0]['label'] == 'positive', \"First text should be positive\"\n\n    # Check second result is negative\n    assert data['results'][1]['label'] == 'negative', \"Second text should be negative\"\n\n    # Test validation error\n    response = client.post(\n        \"/classify/batch\",\n        json={\"texts\": []}  # Empty list\n    )\n    assert response.status_code == 422, \"Empty list should return 422\"\n\nprint(\"✓ Task 4 PASSED!\")\nprint(\"  /classify/batch endpoint working correctly\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 5: Add Health Check and Error Handling\n",
    "\n",
    "Add:\n",
    "1. **GET `/health`**: Returns status and model info\n",
    "2. **GET `/`**: Root endpoint with API info\n",
    "3. **Error handling**: Try-except blocks with proper HTTP exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Add health check and root endpoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "# TEST - Do not modify\nwith TestClient(app) as client:\n    # Test root endpoint\n    response = client.get(\"/\")\n    assert response.status_code == 200\n    data = response.json()\n    assert 'message' in data or 'name' in data, \"Root should return info\"\n\n    # Test health endpoint\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n    data = response.json()\n    assert 'status' in data, \"Health check missing 'status'\"\n    assert data['status'] == 'healthy', f\"Expected healthy, got {data['status']}\"\n\nprint(\"✓ Task 5 PASSED!\")\nprint(\"  Health check and root endpoints working\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Test Full API Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "# Test complete API flow\nwith TestClient(app) as client:\n    print(\"=== Full API Test ===\")\n    print()\n\n    # 1. Health check\n    response = client.get(\"/health\")\n    print(\"1. Health Check:\")\n    print(f\"   {response.json()}\")\n    print()\n\n    # 2. Single classification\n    text = \"This product exceeded all my expectations!\"\n    response = client.post(\"/classify\", json={\"text\": text})\n    result = response.json()\n    print(\"2. Single Classification:\")\n    print(f\"   Text: {text}\")\n    print(f\"   Label: {result['label']}\")\n    print(f\"   Confidence: {result['confidence']:.4f}\")\n    print()\n\n    # 3. Batch classification\n    texts = [\n        \"Absolutely love it!\",\n        \"Worst purchase ever.\",\n        \"It's okay, nothing special.\"\n    ]\n    response = client.post(\"/classify/batch\", json={\"texts\": texts})\n    result = response.json()\n    print(\"3. Batch Classification:\")\n    for i, r in enumerate(result['results']):\n        print(f\"   {i+1}. {r['label']} ({r['confidence']:.4f}): {r['text']}\")\n    print()\n\nprint(\"✓ All tests passed!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "## Expected Results\n",
    "\n",
    "After completing all tasks:\n",
    "- **Task 1**: FastAPI app with lifespan loading models\n",
    "- **Task 2**: Four Pydantic models with validation\n",
    "- **Task 3**: `/classify` endpoint returning single result\n",
    "- **Task 4**: `/classify/batch` endpoint processing multiple texts\n",
    "- **Task 5**: Health check and root endpoints\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "1. **Lifespan**: Load heavy resources (models) once at startup\n",
    "2. **Pydantic**: Automatic validation and serialization\n",
    "3. **Error handling**: Proper HTTP status codes\n",
    "4. **Batch processing**: More efficient than multiple single requests\n",
    "5. **Type hints**: Better IDE support and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}