{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Task 1: Build a Text Classification API - SOLUTION\n",
    "\n",
    "## Scenario\n",
    "Build a production-ready FastAPI service for sentiment classification that:\n",
    "1. Loads a model efficiently using lifespan context\n",
    "2. Validates input/output with Pydantic models\n",
    "3. Provides single and batch classification endpoints\n",
    "4. Includes proper error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from contextlib import asynccontextmanager\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from fastapi import FastAPI, HTTPException, status\n",
    "from fastapi.testclient import TestClient\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "### Helper: Train a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "with open('../fixtures/input/sample_texts.json') as f:\n",
    "    sample_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(sample_data)} samples\")\n",
    "print(f\"\\nSample: {sample_data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple classifier (for demo purposes)\n",
    "def train_simple_classifier():\n",
    "    \"\"\"Train a simple sentiment classifier.\"\"\"\n",
    "    texts = [item['text'] for item in sample_data]\n",
    "    labels = [item['expected_label'] for item in sample_data]\n",
    "    \n",
    "    # Create embeddings\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(texts)\n",
    "    \n",
    "    # Train classifier\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(embeddings, labels)\n",
    "    \n",
    "    return model, clf\n",
    "\n",
    "print(\"Classifier training function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Create Lifespan Context and App - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "# Global dict to store models\n",
    "ml_models = {}\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"Lifespan context manager for loading/unloading models.\"\"\"\n",
    "    # Startup: Load models\n",
    "    print(\"Loading models...\")\n",
    "    encoder, classifier = train_simple_classifier()\n",
    "    ml_models[\"encoder\"] = encoder\n",
    "    ml_models[\"classifier\"] = classifier\n",
    "    print(f\"Models loaded: {list(ml_models.keys())}\")\n",
    "    \n",
    "    yield  # App runs here\n",
    "    \n",
    "    # Shutdown: Cleanup\n",
    "    print(\"Cleaning up models...\")\n",
    "    ml_models.clear()\n",
    "\n",
    "# Create FastAPI app with lifespan\n",
    "app = FastAPI(\n",
    "    title=\"Text Classification API\",\n",
    "    description=\"Sentiment classification service with ML models\",\n",
    "    version=\"1.0.0\",\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "print(\"FastAPI app created with lifespan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert 'ml_models' in dir(), \"ml_models dict not found\"\n",
    "assert 'lifespan' in dir(), \"lifespan function not found\"\n",
    "assert 'app' in dir(), \"app not found\"\n",
    "\n",
    "# Test that models load (context manager triggers lifespan startup)\n",
    "with TestClient(app) as client:\n",
    "    assert 'encoder' in ml_models, \"encoder not loaded in ml_models\"\n",
    "    assert 'classifier' in ml_models, \"classifier not loaded in ml_models\"\n",
    "    print(\"✓ Task 1 PASSED!\")\n",
    "    print(f\"  Models loaded: {list(ml_models.keys())}\")\n",
    "\n",
    "# Re-load models for subsequent cells (lifespan cleanup clears them)\n",
    "encoder, classifier = train_simple_classifier()\n",
    "ml_models[\"encoder\"] = encoder\n",
    "ml_models[\"classifier\"] = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Define Pydantic Models - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "class TextInput(BaseModel):\n",
    "    \"\"\"Input model for single text classification.\"\"\"\n",
    "    text: str = Field(..., min_length=1, max_length=5000, description=\"Text to classify\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"text\": \"This product is amazing!\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "class ClassificationResult(BaseModel):\n",
    "    \"\"\"Output model for classification result.\"\"\"\n",
    "    text: str = Field(..., description=\"Original text\")\n",
    "    label: str = Field(..., description=\"Predicted label\")\n",
    "    confidence: float = Field(..., ge=0.0, le=1.0, description=\"Prediction confidence\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"text\": \"This product is amazing!\",\n",
    "                \"label\": \"positive\",\n",
    "                \"confidence\": 0.95\n",
    "            }\n",
    "        }\n",
    "\n",
    "class BatchTextInput(BaseModel):\n",
    "    \"\"\"Input model for batch text classification.\"\"\"\n",
    "    texts: List[str] = Field(..., min_length=1, max_length=100, description=\"List of texts to classify\")\n",
    "    \n",
    "    @validator('texts')\n",
    "    def validate_texts(cls, v):\n",
    "        \"\"\"Validate each text in the list.\"\"\"\n",
    "        for text in v:\n",
    "            if not text or len(text) == 0:\n",
    "                raise ValueError(\"Each text must be non-empty\")\n",
    "            if len(text) > 5000:\n",
    "                raise ValueError(\"Each text must be <= 5000 characters\")\n",
    "        return v\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"texts\": [\n",
    "                    \"This is great!\",\n",
    "                    \"This is terrible.\",\n",
    "                    \"It's okay.\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "class BatchClassificationResult(BaseModel):\n",
    "    \"\"\"Output model for batch classification.\"\"\"\n",
    "    results: List[ClassificationResult] = Field(..., description=\"List of classification results\")\n",
    "    count: int = Field(..., description=\"Number of texts classified\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"results\": [\n",
    "                    {\"text\": \"Great!\", \"label\": \"positive\", \"confidence\": 0.95},\n",
    "                    {\"text\": \"Terrible.\", \"label\": \"negative\", \"confidence\": 0.92}\n",
    "                ],\n",
    "                \"count\": 2\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"Pydantic models defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert 'TextInput' in dir(), \"TextInput not found\"\n",
    "assert 'ClassificationResult' in dir(), \"ClassificationResult not found\"\n",
    "assert 'BatchTextInput' in dir(), \"BatchTextInput not found\"\n",
    "assert 'BatchClassificationResult' in dir(), \"BatchClassificationResult not found\"\n",
    "\n",
    "# Test validation\n",
    "valid_input = TextInput(text=\"This is a test\")\n",
    "assert valid_input.text == \"This is a test\"\n",
    "\n",
    "try:\n",
    "    TextInput(text=\"\")  # Should fail\n",
    "    assert False, \"Empty text should be rejected\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    TextInput(text=\"a\" * 6000)  # Should fail\n",
    "    assert False, \"Text too long should be rejected\"\n",
    "except:\n",
    "    pass\n",
    "\n",
    "result = ClassificationResult(text=\"test\", label=\"positive\", confidence=0.95)\n",
    "assert 0 <= result.confidence <= 1\n",
    "\n",
    "batch_input = BatchTextInput(texts=[\"text1\", \"text2\"])\n",
    "assert len(batch_input.texts) == 2\n",
    "\n",
    "print(\"✓ Task 2 PASSED!\")\n",
    "print(\"  All Pydantic models defined with proper validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Implement Single Classification Endpoint - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "@app.post(\"/classify\", response_model=ClassificationResult, status_code=status.HTTP_200_OK)\n",
    "async def classify_text(input_data: TextInput):\n",
    "    \"\"\"\n",
    "    Classify a single text.\n",
    "    \n",
    "    Args:\n",
    "        input_data: TextInput with text to classify\n",
    "        \n",
    "    Returns:\n",
    "        ClassificationResult with label and confidence\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get models\n",
    "        encoder = ml_models.get(\"encoder\")\n",
    "        classifier = ml_models.get(\"classifier\")\n",
    "        \n",
    "        if not encoder or not classifier:\n",
    "            raise HTTPException(\n",
    "                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n",
    "                detail=\"Models not loaded\"\n",
    "            )\n",
    "        \n",
    "        # Encode text\n",
    "        embedding = encoder.encode([input_data.text])\n",
    "        \n",
    "        # Predict\n",
    "        label = classifier.predict(embedding)[0]\n",
    "        \n",
    "        # Get confidence (max probability)\n",
    "        probabilities = classifier.predict_proba(embedding)[0]\n",
    "        confidence = float(np.max(probabilities))\n",
    "        \n",
    "        return ClassificationResult(\n",
    "            text=input_data.text,\n",
    "            label=label,\n",
    "            confidence=confidence\n",
    "        )\n",
    "        \n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n",
    "            detail=f\"Classification failed: {str(e)}\"\n",
    "        )\n",
    "\n",
    "print(\"/classify endpoint implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "with TestClient(app) as client:\n",
    "    # Test positive sentiment\n",
    "    response = client.post(\n",
    "        \"/classify\",\n",
    "        json={\"text\": \"This is amazing! I love it!\"}\n",
    "    )\n",
    "    assert response.status_code == 200, f\"Expected 200, got {response.status_code}\"\n",
    "    data = response.json()\n",
    "    assert 'label' in data, \"Response missing 'label'\"\n",
    "    assert 'confidence' in data, \"Response missing 'confidence'\"\n",
    "    assert 'text' in data, \"Response missing 'text'\"\n",
    "    assert 0 <= data['confidence'] <= 1, \"Confidence should be between 0 and 1\"\n",
    "    assert data['label'] == 'positive', f\"Expected 'positive', got {data['label']}\"\n",
    "\n",
    "    # Test negative sentiment\n",
    "    response = client.post(\n",
    "        \"/classify\",\n",
    "        json={\"text\": \"This is terrible and awful!\"}\n",
    "    )\n",
    "    assert response.status_code == 200\n",
    "    data = response.json()\n",
    "    assert data['label'] == 'negative', f\"Expected 'negative', got {data['label']}\"\n",
    "\n",
    "    # Test validation error\n",
    "    response = client.post(\n",
    "        \"/classify\",\n",
    "        json={\"text\": \"\"}  # Empty text\n",
    "    )\n",
    "    assert response.status_code == 422, \"Empty text should return 422\"\n",
    "\n",
    "print(\"✓ Task 3 PASSED!\")\n",
    "print(\"  /classify endpoint working correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4: Implement Batch Classification Endpoint - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "@app.post(\"/classify/batch\", response_model=BatchClassificationResult, status_code=status.HTTP_200_OK)\n",
    "async def classify_batch(input_data: BatchTextInput):\n",
    "    \"\"\"\n",
    "    Classify multiple texts in batch.\n",
    "    \n",
    "    Args:\n",
    "        input_data: BatchTextInput with list of texts\n",
    "        \n",
    "    Returns:\n",
    "        BatchClassificationResult with all results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get models\n",
    "        encoder = ml_models.get(\"encoder\")\n",
    "        classifier = ml_models.get(\"classifier\")\n",
    "        \n",
    "        if not encoder or not classifier:\n",
    "            raise HTTPException(\n",
    "                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n",
    "                detail=\"Models not loaded\"\n",
    "            )\n",
    "        \n",
    "        # Encode all texts in batch (more efficient)\n",
    "        embeddings = encoder.encode(input_data.texts)\n",
    "        \n",
    "        # Predict for all texts\n",
    "        labels = classifier.predict(embeddings)\n",
    "        \n",
    "        # Get probabilities for confidence\n",
    "        probabilities = classifier.predict_proba(embeddings)\n",
    "        confidences = np.max(probabilities, axis=1)\n",
    "        \n",
    "        # Build results list\n",
    "        results = [\n",
    "            ClassificationResult(\n",
    "                text=text,\n",
    "                label=label,\n",
    "                confidence=float(confidence)\n",
    "            )\n",
    "            for text, label, confidence in zip(input_data.texts, labels, confidences)\n",
    "        ]\n",
    "        \n",
    "        return BatchClassificationResult(\n",
    "            results=results,\n",
    "            count=len(results)\n",
    "        )\n",
    "        \n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n",
    "            detail=f\"Batch classification failed: {str(e)}\"\n",
    "        )\n",
    "\n",
    "print(\"/classify/batch endpoint implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "with TestClient(app) as client:\n",
    "    # Test batch classification\n",
    "    response = client.post(\n",
    "        \"/classify/batch\",\n",
    "        json={\n",
    "            \"texts\": [\n",
    "                \"This is amazing!\",\n",
    "                \"Terrible quality. Complete waste of money.\",\n",
    "                \"The package arrived today.\"\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    assert response.status_code == 200, f\"Expected 200, got {response.status_code}\"\n",
    "    data = response.json()\n",
    "    assert 'results' in data, \"Response missing 'results'\"\n",
    "    assert 'count' in data, \"Response missing 'count'\"\n",
    "    assert data['count'] == 3, f\"Expected count=3, got {data['count']}\"\n",
    "    assert len(data['results']) == 3, f\"Expected 3 results, got {len(data['results'])}\"\n",
    "\n",
    "    # Check first result is positive\n",
    "    assert data['results'][0]['label'] == 'positive', \"First text should be positive\"\n",
    "\n",
    "    # Check second result is negative\n",
    "    assert data['results'][1]['label'] == 'negative', \"Second text should be negative\"\n",
    "\n",
    "    # Test validation error\n",
    "    response = client.post(\n",
    "        \"/classify/batch\",\n",
    "        json={\"texts\": []}  # Empty list\n",
    "    )\n",
    "    assert response.status_code == 422, \"Empty list should return 422\"\n",
    "\n",
    "print(\"✓ Task 4 PASSED!\")\n",
    "print(\"  /classify/batch endpoint working correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 5: Add Health Check and Error Handling - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "@app.get(\"/\", status_code=status.HTTP_200_OK)\n",
    "async def root():\n",
    "    \"\"\"Root endpoint with API information.\"\"\"\n",
    "    return {\n",
    "        \"name\": \"Text Classification API\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"description\": \"Sentiment classification service\",\n",
    "        \"endpoints\": {\n",
    "            \"classify\": \"/classify\",\n",
    "            \"batch_classify\": \"/classify/batch\",\n",
    "            \"health\": \"/health\",\n",
    "            \"docs\": \"/docs\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "@app.get(\"/health\", status_code=status.HTTP_200_OK)\n",
    "async def health_check():\n",
    "    \"\"\"Health check endpoint.\"\"\"\n",
    "    models_loaded = \"encoder\" in ml_models and \"classifier\" in ml_models\n",
    "    \n",
    "    if not models_loaded:\n",
    "        raise HTTPException(\n",
    "            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n",
    "            detail=\"Models not loaded\"\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"models_loaded\": list(ml_models.keys()),\n",
    "        \"model_info\": {\n",
    "            \"encoder\": type(ml_models[\"encoder\"]).__name__,\n",
    "            \"classifier\": type(ml_models[\"classifier\"]).__name__\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"Health check and root endpoints added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "with TestClient(app) as client:\n",
    "    # Test root endpoint\n",
    "    response = client.get(\"/\")\n",
    "    assert response.status_code == 200\n",
    "    data = response.json()\n",
    "    assert 'message' in data or 'name' in data, \"Root should return info\"\n",
    "\n",
    "    # Test health endpoint\n",
    "    response = client.get(\"/health\")\n",
    "    assert response.status_code == 200\n",
    "    data = response.json()\n",
    "    assert 'status' in data, \"Health check missing 'status'\"\n",
    "    assert data['status'] == 'healthy', f\"Expected healthy, got {data['status']}\"\n",
    "\n",
    "print(\"✓ Task 5 PASSED!\")\n",
    "print(\"  Health check and root endpoints working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Test Full API Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test complete API flow\n",
    "with TestClient(app) as client:\n",
    "    print(\"=== Full API Test ===\")\n",
    "    print()\n",
    "\n",
    "    # 1. Health check\n",
    "    response = client.get(\"/health\")\n",
    "    print(\"1. Health Check:\")\n",
    "    print(f\"   {response.json()}\")\n",
    "    print()\n",
    "\n",
    "    # 2. Single classification\n",
    "    text = \"This product exceeded all my expectations!\"\n",
    "    response = client.post(\"/classify\", json={\"text\": text})\n",
    "    result = response.json()\n",
    "    print(\"2. Single Classification:\")\n",
    "    print(f\"   Text: {text}\")\n",
    "    print(f\"   Label: {result['label']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.4f}\")\n",
    "    print()\n",
    "\n",
    "    # 3. Batch classification\n",
    "    texts = [\n",
    "        \"Absolutely love it!\",\n",
    "        \"Worst purchase ever.\",\n",
    "        \"It's okay, nothing special.\"\n",
    "    ]\n",
    "    response = client.post(\"/classify/batch\", json={\"texts\": texts})\n",
    "    result = response.json()\n",
    "    print(\"3. Batch Classification:\")\n",
    "    for i, r in enumerate(result['results']):\n",
    "        print(f\"   {i+1}. {r['label']} ({r['confidence']:.4f}): {r['text']}\")\n",
    "    print()\n",
    "\n",
    "print(\"✓ All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "**Key techniques used:**\n",
    "\n",
    "1. **Lifespan context manager:**\n",
    "   - Load models once at startup\n",
    "   - Store in global dict accessible to all endpoints\n",
    "   - Clean up on shutdown\n",
    "\n",
    "2. **Pydantic models:**\n",
    "   - Automatic validation (min/max length)\n",
    "   - Type checking and conversion\n",
    "   - API documentation generation\n",
    "   - Custom validators with `@validator`\n",
    "\n",
    "3. **Error handling:**\n",
    "   - Use `HTTPException` with proper status codes\n",
    "   - 422 for validation errors (automatic)\n",
    "   - 503 for service unavailable\n",
    "   - 500 for internal errors\n",
    "\n",
    "4. **Batch processing:**\n",
    "   - Encode all texts at once (more efficient)\n",
    "   - Single predict call for all inputs\n",
    "   - Build results list with list comprehension\n",
    "\n",
    "5. **Type hints:**\n",
    "   - Better IDE support\n",
    "   - Automatic OpenAPI documentation\n",
    "   - Runtime validation\n",
    "\n",
    "**Common pitfalls avoided:**\n",
    "- Loading models in each request (slow)\n",
    "- Not validating input length\n",
    "- Processing batch items one at a time\n",
    "- Not handling model loading failures\n",
    "- Using generic error messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
