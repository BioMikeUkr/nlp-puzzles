{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Async Operations and Background Tasks\n",
    "\n",
    "This notebook covers async operations in FastAPI:\n",
    "- Async vs sync endpoints\n",
    "- File uploads with UploadFile\n",
    "- Background tasks for processing\n",
    "- Streaming responses\n",
    "- Concurrent request handling\n",
    "\n",
    "FastAPI is built on ASGI (async) which enables high-performance concurrent request handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from fastapi import FastAPI, File, Form, UploadFile, BackgroundTasks, HTTPException, status\nfrom fastapi.responses import StreamingResponse, JSONResponse\nfrom fastapi.testclient import TestClient\nfrom pydantic import BaseModel, Field, EmailStr\nfrom typing import List, Optional, Generator\nimport asyncio\nimport aiofiles\nimport time\nfrom datetime import datetime\nimport json\nimport io\nfrom pathlib import Path\nimport tempfile"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Async vs Sync Endpoints\n",
    "\n",
    "FastAPI supports both async and sync endpoints. Understanding when to use each is important for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "app = FastAPI(\n    title=\"Async Operations API\",\n    description=\"Demonstrating async operations, file uploads, and background tasks\",\n    version=\"1.0.0\"\n)\n\n# Sync endpoint - runs in threadpool\n@app.get(\"/sync/sleep/{seconds}\")\ndef sync_sleep(seconds: int):\n    \"\"\"Sync endpoint - blocks the thread\"\"\"\n    time.sleep(seconds)\n    return {\n        \"type\": \"sync\",\n        \"slept_for\": seconds,\n        \"message\": f\"Slept for {seconds} seconds (blocking)\"\n    }\n\n# Async endpoint - non-blocking\n@app.get(\"/async/sleep/{seconds}\")\nasync def async_sleep(seconds: int):\n    \"\"\"Async endpoint - non-blocking\"\"\"\n    await asyncio.sleep(seconds)\n    return {\n        \"type\": \"async\",\n        \"slept_for\": seconds,\n        \"message\": f\"Slept for {seconds} seconds (non-blocking)\"\n    }\n\n# Async endpoint with external API call (simulated)\n@app.get(\"/async/fetch\")\nasync def fetch_external_data(delay: int = 1):\n    \"\"\"Async endpoint making external HTTP request (simulated)\"\"\"\n    start_time = time.time()\n    \n    # Simulate async HTTP request\n    await asyncio.sleep(delay)\n    data = {\"status\": \"success\", \"delay\": delay}\n    \n    elapsed = (time.time() - start_time) * 1000\n    \n    return {\n        \"message\": \"Fetched data successfully\",\n        \"elapsed_ms\": round(elapsed, 2),\n        \"data\": data\n    }\n\n# CPU-bound operation - use sync\n@app.get(\"/sync/compute\")\ndef compute_fibonacci(n: int = 30):\n    \"\"\"CPU-bound operation - better as sync\"\"\"\n    def fib(x):\n        if x <= 1:\n            return x\n        return fib(x-1) + fib(x-2)\n    \n    start_time = time.time()\n    result = fib(n)\n    elapsed = (time.time() - start_time) * 1000\n    \n    return {\n        \"n\": n,\n        \"result\": result,\n        \"elapsed_ms\": round(elapsed, 2),\n        \"note\": \"CPU-bound, runs in threadpool\"\n    }\n\nprint(\"Async vs Sync endpoints added!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. File Upload Endpoints\n",
    "\n",
    "FastAPI provides excellent support for file uploads using `UploadFile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Temporary directory for uploaded files\nUPLOAD_DIR = Path(tempfile.gettempdir()) / \"fastapi_uploads\"\nUPLOAD_DIR.mkdir(exist_ok=True)\n\nclass FileUploadResponse(BaseModel):\n    filename: str\n    content_type: str\n    size_bytes: int\n    saved_to: str\n    upload_time_ms: float\n\n# Single file upload\n@app.post(\"/upload/file\", response_model=FileUploadResponse)\nasync def upload_file(file: UploadFile = File(...)):\n    \"\"\"Upload a single file\"\"\"\n    start_time = time.time()\n    \n    # Read file content\n    content = await file.read()\n    file_size = len(content)\n    \n    # Save file\n    file_path = UPLOAD_DIR / file.filename\n    async with aiofiles.open(file_path, 'wb') as f:\n        await f.write(content)\n    \n    elapsed = (time.time() - start_time) * 1000\n    \n    return {\n        \"filename\": file.filename,\n        \"content_type\": file.content_type,\n        \"size_bytes\": file_size,\n        \"saved_to\": str(file_path),\n        \"upload_time_ms\": round(elapsed, 2)\n    }\n\n# Multiple file upload\n@app.post(\"/upload/files\")\nasync def upload_multiple_files(files: List[UploadFile] = File(...)):\n    \"\"\"Upload multiple files\"\"\"\n    start_time = time.time()\n    results = []\n    \n    for file in files:\n        content = await file.read()\n        file_size = len(content)\n        \n        file_path = UPLOAD_DIR / file.filename\n        async with aiofiles.open(file_path, 'wb') as f:\n            await f.write(content)\n        \n        results.append({\n            \"filename\": file.filename,\n            \"size_bytes\": file_size,\n            \"content_type\": file.content_type\n        })\n    \n    elapsed = (time.time() - start_time) * 1000\n    \n    return {\n        \"files_uploaded\": len(results),\n        \"total_size_bytes\": sum(r[\"size_bytes\"] for r in results),\n        \"upload_time_ms\": round(elapsed, 2),\n        \"files\": results\n    }\n\n# Upload with metadata\nclass FileMetadata(BaseModel):\n    description: str\n    tags: List[str] = []\n    category: str\n\n@app.post(\"/upload/with-metadata\")\nasync def upload_with_metadata(\n    file: UploadFile = File(...),\n    description: str = Form(...),\n    tags: str = Form(default=\"\"),  # Comma-separated\n    category: str = Form(...)\n):\n    \"\"\"Upload file with metadata\"\"\"\n    content = await file.read()\n    \n    file_path = UPLOAD_DIR / file.filename\n    async with aiofiles.open(file_path, 'wb') as f:\n        await f.write(content)\n    \n    # Save metadata\n    metadata = {\n        \"filename\": file.filename,\n        \"description\": description,\n        \"tags\": [t.strip() for t in tags.split(\",\") if t.strip()],\n        \"category\": category,\n        \"uploaded_at\": datetime.now().isoformat(),\n        \"size_bytes\": len(content)\n    }\n    \n    metadata_path = UPLOAD_DIR / f\"{file.filename}.json\"\n    async with aiofiles.open(metadata_path, 'w') as f:\n        await f.write(json.dumps(metadata, indent=2))\n    \n    return metadata\n\nprint(\"File upload endpoints added!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Background Tasks\n",
    "\n",
    "Background tasks run after the response is sent to the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated task log\n",
    "task_log = []\n",
    "\n",
    "def log_task(message: str):\n",
    "    \"\"\"Background task: log message with timestamp\"\"\"\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    log_entry = f\"[{timestamp}] {message}\"\n",
    "    task_log.append(log_entry)\n",
    "    print(log_entry)\n",
    "\n",
    "async def send_email_notification(email: str, subject: str, message: str):\n",
    "    \"\"\"Background task: simulate sending email\"\"\"\n",
    "    await asyncio.sleep(2)  # Simulate email sending\n",
    "    log_entry = f\"Email sent to {email}: {subject}\"\n",
    "    task_log.append(log_entry)\n",
    "    print(log_entry)\n",
    "\n",
    "async def process_file_in_background(file_path: str, filename: str):\n",
    "    \"\"\"Background task: process uploaded file\"\"\"\n",
    "    await asyncio.sleep(3)  # Simulate processing\n",
    "    log_entry = f\"File processed: {filename}\"\n",
    "    task_log.append(log_entry)\n",
    "    print(log_entry)\n",
    "\n",
    "# Endpoint with background task\n",
    "class UserRegistration(BaseModel):\n",
    "    username: str\n",
    "    email: EmailStr\n",
    "    full_name: str\n",
    "\n",
    "@app.post(\"/users/register\")\n",
    "async def register_user(user: UserRegistration, background_tasks: BackgroundTasks):\n",
    "    \"\"\"Register user and send welcome email in background\"\"\"\n",
    "    # Add background tasks\n",
    "    background_tasks.add_task(\n",
    "        log_task,\n",
    "        f\"User registered: {user.username}\"\n",
    "    )\n",
    "    background_tasks.add_task(\n",
    "        send_email_notification,\n",
    "        user.email,\n",
    "        \"Welcome!\",\n",
    "        f\"Welcome to our service, {user.full_name}!\"\n",
    "    )\n",
    "    \n",
    "    # Return immediately (background tasks run after response)\n",
    "    return {\n",
    "        \"message\": \"Registration successful\",\n",
    "        \"username\": user.username,\n",
    "        \"email\": user.email,\n",
    "        \"note\": \"Welcome email will be sent shortly\"\n",
    "    }\n",
    "\n",
    "# File upload with background processing\n",
    "@app.post(\"/upload/process\")\n",
    "async def upload_and_process(file: UploadFile, background_tasks: BackgroundTasks):\n",
    "    \"\"\"Upload file and process in background\"\"\"\n",
    "    # Save file\n",
    "    content = await file.read()\n",
    "    file_path = UPLOAD_DIR / file.filename\n",
    "    \n",
    "    async with aiofiles.open(file_path, 'wb') as f:\n",
    "        await f.write(content)\n",
    "    \n",
    "    # Add background processing task\n",
    "    background_tasks.add_task(\n",
    "        process_file_in_background,\n",
    "        str(file_path),\n",
    "        file.filename\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"message\": \"File uploaded successfully\",\n",
    "        \"filename\": file.filename,\n",
    "        \"size_bytes\": len(content),\n",
    "        \"status\": \"processing in background\"\n",
    "    }\n",
    "\n",
    "# View task log\n",
    "@app.get(\"/tasks/log\")\n",
    "async def get_task_log():\n",
    "    \"\"\"Get background task log\"\"\"\n",
    "    return {\n",
    "        \"total_tasks\": len(task_log),\n",
    "        \"log\": task_log[-20:]  # Last 20 entries\n",
    "    }\n",
    "\n",
    "print(\"Background task endpoints added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Streaming Responses\n",
    "\n",
    "Stream data to clients as it becomes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator function for streaming\n",
    "async def generate_numbers(n: int):\n",
    "    \"\"\"Generate numbers with delay\"\"\"\n",
    "    for i in range(n):\n",
    "        await asyncio.sleep(0.1)  # Simulate computation\n",
    "        yield f\"Number: {i}\\n\"\n",
    "\n",
    "async def generate_log_stream():\n",
    "    \"\"\"Generate simulated log stream\"\"\"\n",
    "    log_messages = [\n",
    "        \"Starting application...\",\n",
    "        \"Loading configuration...\",\n",
    "        \"Connecting to database...\",\n",
    "        \"Database connected\",\n",
    "        \"Loading models...\",\n",
    "        \"Models loaded\",\n",
    "        \"Application ready\",\n",
    "    ]\n",
    "    \n",
    "    for msg in log_messages:\n",
    "        await asyncio.sleep(0.5)\n",
    "        timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        yield f\"[{timestamp}] {msg}\\n\"\n",
    "\n",
    "# Streaming endpoint\n",
    "@app.get(\"/stream/numbers\")\n",
    "async def stream_numbers(count: int = 10):\n",
    "    \"\"\"Stream numbers to client\"\"\"\n",
    "    return StreamingResponse(\n",
    "        generate_numbers(count),\n",
    "        media_type=\"text/plain\"\n",
    "    )\n",
    "\n",
    "@app.get(\"/stream/logs\")\n",
    "async def stream_logs():\n",
    "    \"\"\"Stream simulated logs\"\"\"\n",
    "    return StreamingResponse(\n",
    "        generate_log_stream(),\n",
    "        media_type=\"text/plain\"\n",
    "    )\n",
    "\n",
    "# Stream JSON data\n",
    "async def generate_json_stream(items: int):\n",
    "    \"\"\"Generate JSON objects\"\"\"\n",
    "    for i in range(items):\n",
    "        await asyncio.sleep(0.2)\n",
    "        data = {\n",
    "            \"id\": i,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"value\": i * 10\n",
    "        }\n",
    "        yield json.dumps(data) + \"\\n\"\n",
    "\n",
    "@app.get(\"/stream/json\")\n",
    "async def stream_json(items: int = 5):\n",
    "    \"\"\"Stream JSON objects (newline-delimited JSON)\"\"\"\n",
    "    return StreamingResponse(\n",
    "        generate_json_stream(items),\n",
    "        media_type=\"application/x-ndjson\"\n",
    "    )\n",
    "\n",
    "# Simulate LLM streaming\n",
    "async def generate_llm_response(prompt: str):\n",
    "    \"\"\"Simulate LLM token streaming\"\"\"\n",
    "    response = f\"This is a response to: '{prompt}'. The answer involves multiple tokens being streamed.\"\n",
    "    words = response.split()\n",
    "    \n",
    "    for word in words:\n",
    "        await asyncio.sleep(0.1)  # Simulate token generation\n",
    "        yield word + \" \"\n",
    "\n",
    "@app.get(\"/stream/llm\")\n",
    "async def stream_llm(prompt: str = \"What is FastAPI?\"):\n",
    "    \"\"\"Stream LLM-style response\"\"\"\n",
    "    return StreamingResponse(\n",
    "        generate_llm_response(prompt),\n",
    "        media_type=\"text/plain\"\n",
    "    )\n",
    "\n",
    "print(\"Streaming endpoints added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Concurrent Request Handling\n",
    "\n",
    "Demonstrate FastAPI's ability to handle concurrent requests efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track concurrent requests\n",
    "active_requests = {\"count\": 0}\n",
    "request_history = []\n",
    "\n",
    "@app.get(\"/concurrent/slow\")\n",
    "async def slow_endpoint(delay: int = 2, request_id: str = \"unknown\"):\n",
    "    \"\"\"Slow endpoint for testing concurrency\"\"\"\n",
    "    active_requests[\"count\"] += 1\n",
    "    max_concurrent = active_requests[\"count\"]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    await asyncio.sleep(delay)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    active_requests[\"count\"] -= 1\n",
    "    \n",
    "    result = {\n",
    "        \"request_id\": request_id,\n",
    "        \"delay\": delay,\n",
    "        \"elapsed\": round(elapsed, 2),\n",
    "        \"concurrent_requests_during_processing\": max_concurrent\n",
    "    }\n",
    "    \n",
    "    request_history.append(result)\n",
    "    return result\n",
    "\n",
    "@app.get(\"/concurrent/stats\")\n",
    "async def concurrent_stats():\n",
    "    \"\"\"Get concurrency statistics\"\"\"\n",
    "    return {\n",
    "        \"current_active\": active_requests[\"count\"],\n",
    "        \"total_processed\": len(request_history),\n",
    "        \"recent_requests\": request_history[-10:]\n",
    "    }\n",
    "\n",
    "print(\"Concurrent handling endpoints added!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Running the Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create TestClient\nclient = TestClient(app)\n\nprint(f\"\\nâœ… Client ready for testing\")\nprint(f\"ðŸ“š The app would normally run at http://127.0.0.1:8000/docs in production\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing Async Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 1: Async vs Sync sleep\nprint(\"Test 1 - Async vs Sync:\")\n\n# Async endpoint\nstart = time.time()\nresponse = client.get(\"/async/sleep/1\")\nasync_time = time.time() - start\nprint(f\"Async sleep: {async_time:.2f}s\")\n\n# Sync endpoint\nstart = time.time()\nresponse = client.get(\"/sync/sleep/1\")\nsync_time = time.time() - start\nprint(f\"Sync sleep: {sync_time:.2f}s\")\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 2: File upload\nprint(\"Test 2 - File upload:\")\n\n# Create test file\nfile_content = b\"This is a test file for FastAPI upload demonstration.\"\nfiles = {\"file\": (\"test.txt\", file_content, \"text/plain\")}\n\nresponse = client.post(\"/upload/file\", files=files)\nresult = response.json()\nprint(f\"Uploaded: {result['filename']}\")\nprint(f\"Size: {result['size_bytes']} bytes\")\nprint(f\"Upload time: {result['upload_time_ms']:.2f}ms\")\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 3: Multiple file upload\nprint(\"Test 3 - Multiple file upload:\")\n\nfiles = [\n    (\"files\", (\"file1.txt\", b\"Content of file 1\", \"text/plain\")),\n    (\"files\", (\"file2.txt\", b\"Content of file 2\", \"text/plain\")),\n    (\"files\", (\"file3.txt\", b\"Content of file 3\", \"text/plain\")),\n]\n\nresponse = client.post(\"/upload/files\", files=files)\nresult = response.json()\nprint(f\"Files uploaded: {result['files_uploaded']}\")\nprint(f\"Total size: {result['total_size_bytes']} bytes\")\nprint(f\"Upload time: {result['upload_time_ms']:.2f}ms\")\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 4: Background tasks\nprint(\"Test 4 - Background tasks:\")\n\nuser_data = {\n    \"username\": \"testuser\",\n    \"email\": \"test@example.com\",\n    \"full_name\": \"Test User\"\n}\n\nresponse = client.post(\"/users/register\", json=user_data)\nresult = response.json()\nprint(f\"Response: {result['message']}\")\nprint(f\"Note: {result['note']}\")\nprint(\"\\nWaiting for background tasks to complete...\")\ntime.sleep(3)\n\n# Check task log\nresponse = client.get(\"/tasks/log\")\nlog_data = response.json()\nprint(f\"\\nTask log ({log_data['total_tasks']} tasks):\")\nfor entry in log_data['log'][-3:]:\n    print(f\"  {entry}\")\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 5: Streaming response\nprint(\"Test 5 - Streaming response:\")\n\nwith client.stream(\"GET\", \"/stream/numbers?count=5\") as response:\n    print(\"Receiving stream:\")\n    for line in response.iter_lines():\n        print(f\"  {line}\")\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 6: Concurrent requests\nprint(\"Test 6 - Concurrent requests:\")\nimport concurrent.futures\n\ndef make_request(request_id):\n    response = client.get(f\"/concurrent/slow?delay=2&request_id=req_{request_id}\")\n    return response.json()\n\n# Make 5 concurrent requests\nprint(\"Making 5 concurrent requests (2s delay each)...\")\nstart_time = time.time()\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n    futures = [executor.submit(make_request, i) for i in range(5)]\n    results = [f.result() for f in concurrent.futures.as_completed(futures)]\n\ntotal_time = time.time() - start_time\n\nprint(f\"\\nTotal time: {total_time:.2f}s (should be ~2s, not 10s!)\")\nprint(\"This demonstrates async concurrency - all requests processed simultaneously\")\n\n# Get stats\nresponse = client.get(\"/concurrent/stats\")\nstats = response.json()\nprint(f\"\\nTotal requests processed: {stats['total_processed']}\")\nprint()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 7: File upload with background processing\nprint(\"Test 7 - File upload with background processing:\")\n\nfile_content = b\"Large file content that needs processing...\"\nfiles = {\"file\": (\"process_me.txt\", file_content, \"text/plain\")}\n\nresponse = client.post(\"/upload/process\", files=files)\nresult = response.json()\nprint(f\"Response: {result['message']}\")\nprint(f\"Status: {result['status']}\")\nprint(\"\\nResponse returned immediately, processing in background...\")\nprint(\"Waiting 4 seconds for background processing...\")\ntime.sleep(4)\n\n# Check task log\nresponse = client.get(\"/tasks/log\")\nlog_data = response.json()\nprint(f\"\\nRecent tasks:\")\nfor entry in log_data['log'][-2:]:\n    print(f\"  {entry}\")\nprint()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways\n",
    "\n",
    "### What we learned:\n",
    "\n",
    "1. **Async vs Sync**:\n",
    "   - Use `async def` for I/O-bound operations (HTTP requests, file I/O, database)\n",
    "   - Use regular `def` for CPU-bound operations (runs in threadpool)\n",
    "   - Async endpoints don't block other requests\n",
    "   - Use `await` for async operations, never use blocking `time.sleep()`\n",
    "\n",
    "2. **File Uploads**:\n",
    "   - `UploadFile` provides efficient file upload handling\n",
    "   - Supports single and multiple file uploads\n",
    "   - Use `aiofiles` for async file I/O\n",
    "   - Can combine file uploads with other form data\n",
    "\n",
    "3. **Background Tasks**:\n",
    "   - Use `BackgroundTasks` for operations after response\n",
    "   - Good for: sending emails, logging, processing files\n",
    "   - Tasks run after response is sent (faster response)\n",
    "   - Multiple tasks can be added to a single response\n",
    "\n",
    "4. **Streaming Responses**:\n",
    "   - Use `StreamingResponse` for large data or real-time updates\n",
    "   - Generator functions with `yield` produce stream\n",
    "   - Good for: logs, LLM responses, large files\n",
    "   - Client receives data as it's generated\n",
    "\n",
    "5. **Concurrency**:\n",
    "   - FastAPI handles concurrent requests efficiently\n",
    "   - Async endpoints can process multiple requests simultaneously\n",
    "   - 5 requests with 2s delay = ~2s total (not 10s!)\n",
    "   - No need for manual thread/process management\n",
    "\n",
    "### Best Practices:\n",
    "- Use async for I/O-bound operations\n",
    "- Use sync for CPU-bound operations\n",
    "- Offload long tasks to background tasks\n",
    "- Stream large responses instead of loading in memory\n",
    "- Set appropriate timeouts for async operations\n",
    "- Clean up uploaded files periodically\n",
    "\n",
    "### Next steps:\n",
    "- In the next notebook, we'll cover authentication and security\n",
    "- We'll implement API keys, JWT tokens, rate limiting, and CORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"\\nðŸŽ‰ Congratulations! You've completed Async Operations!\\n\")\nprint(f\"Client ready for testing!\")\nprint(f\"In production, run: uvicorn app:app --host 0.0.0.0 --port 8000\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}