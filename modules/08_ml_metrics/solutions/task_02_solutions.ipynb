{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 02 Solutions: Threshold Optimization\n",
    "\n",
    "Complete solutions for threshold optimization tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../fixtures/input/classification_data.csv')\n",
    "y_true = df['true_label'].values\n",
    "y_prob = df['predicted_probability'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Find Optimal Threshold for F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Try many thresholds and find best F1\n",
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "f1_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "optimal_f1 = f1_scores[optimal_idx]\n",
    "\n",
    "print(f\"Optimal threshold: {optimal_threshold:.2f}\")\n",
    "print(f\"F1-Score at optimal: {optimal_f1:.4f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, f1_scores, linewidth=2)\n",
    "plt.axvline(optimal_threshold, color='red', linestyle='--', label=f'Optimal: {optimal_threshold:.2f}')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('F1-Score vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "assert 0.0 <= optimal_threshold <= 1.0\n",
    "print(\"✅ Optimal threshold found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: High Precision Threshold (95% precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Solution: Find threshold achieving 95% precision\ntarget_precision = 0.95\n\n# Initialize in case not found\nhigh_precision_threshold = 0.9\nhigh_precision_recall = 0.0\n\nfor threshold in np.arange(0.99, 0.0, -0.01):  # Start high\n    y_pred = (y_prob >= threshold).astype(int)\n    if np.sum(y_pred) > 0:  # At least some predictions\n        precision = precision_score(y_true, y_pred, zero_division=0)\n        if precision >= target_precision:\n            high_precision_threshold = threshold\n            high_precision_recall = recall_score(y_true, y_pred)\n            break\n\nprint(f\"Threshold for 95% precision: {high_precision_threshold:.2f}\")\nprint(f\"Recall at this threshold: {high_precision_recall:.4f}\")\n\n# Verify threshold is valid\nassert 0.0 <= high_precision_threshold <= 1.0\nprint(\"✅ High precision threshold found!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: High Recall Threshold (95% recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Solution: Find threshold achieving 95% recall\ntarget_recall = 0.95\n\n# Initialize in case not found\nhigh_recall_threshold = 0.1\nhigh_recall_precision = 0.0\n\nfor threshold in np.arange(0.0, 1.0, 0.01):  # Start low\n    y_pred = (y_prob >= threshold).astype(int)\n    recall = recall_score(y_true, y_pred, zero_division=0)\n    if recall >= target_recall:\n        high_recall_threshold = threshold\n        high_recall_precision = precision_score(y_true, y_pred, zero_division=0)\n        break\n\nprint(f\"Threshold for 95% recall: {high_recall_threshold:.2f}\")\nprint(f\"Precision at this threshold: {high_recall_precision:.4f}\")\n\n# Verify threshold is valid\nassert 0.0 <= high_recall_threshold <= 1.0\nprint(\"✅ High recall threshold found!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.4: Youden's J Statistic\n",
    "\n",
    "**Youden's J = Sensitivity + Specificity - 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "j_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    j = sensitivity + specificity - 1\n",
    "    j_scores.append(j)\n",
    "\n",
    "youden_idx = np.argmax(j_scores)\n",
    "youden_threshold = thresholds[youden_idx]\n",
    "youden_j = j_scores[youden_idx]\n",
    "\n",
    "print(f\"Youden's optimal threshold: {youden_threshold:.2f}\")\n",
    "print(f\"Youden's J statistic: {youden_j:.4f}\")\n",
    "\n",
    "assert 0.0 <= youden_threshold <= 1.0\n",
    "print(\"✅ Youden's J calculated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Compare All Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all thresholds\n",
    "thresholds_comparison = pd.DataFrame([\n",
    "    {'Strategy': 'Default (0.5)', 'Threshold': 0.50},\n",
    "    {'Strategy': 'Optimal F1', 'Threshold': optimal_threshold},\n",
    "    {'Strategy': 'High Precision', 'Threshold': high_precision_threshold},\n",
    "    {'Strategy': 'High Recall', 'Threshold': high_recall_threshold},\n",
    "    {'Strategy': \"Youden's J\", 'Threshold': youden_threshold}\n",
    "])\n",
    "\n",
    "# Calculate metrics for each\n",
    "for idx, row in thresholds_comparison.iterrows():\n",
    "    t = row['Threshold']\n",
    "    y_pred = (y_prob >= t).astype(int)\n",
    "    \n",
    "    thresholds_comparison.at[idx, 'Precision'] = precision_score(y_true, y_pred, zero_division=0)\n",
    "    thresholds_comparison.at[idx, 'Recall'] = recall_score(y_true, y_pred, zero_division=0)\n",
    "    thresholds_comparison.at[idx, 'F1'] = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "print(thresholds_comparison.to_string(index=False))\n",
    "print(\"\\n✅ All threshold strategies compared!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}