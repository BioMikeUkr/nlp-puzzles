{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Essentials\n",
    "\n",
    "This notebook covers core Pandas operations needed for data processing in ML/NLP pipelines.\n",
    "\n",
    "## Topics:\n",
    "1. Loading data (CSV, JSON)\n",
    "2. Filtering and querying\n",
    "3. Transformations\n",
    "4. Grouping and aggregation\n",
    "5. Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load sample data\n",
    "df = pd.read_csv(\"../fixtures/input/tickets.csv\")\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumn types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for categorical columns\n",
    "print(\"Categories:\")\n",
    "print(df[\"category\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filtering Data\n",
    "\n",
    "Multiple ways to filter DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Boolean indexing\n",
    "software_tickets = df[df[\"category\"] == \"Software Installation\"]\n",
    "print(f\"Software tickets: {len(software_tickets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Multiple conditions\n",
    "filtered = df[\n",
    "    (df[\"category\"] == \"Software Installation\") |\n",
    "    (df[\"category\"] == \"Network Issues\")\n",
    "]\n",
    "print(f\"Software + Network: {len(filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Using query() - cleaner for complex conditions\n",
    "categories = [\"Software Installation\", \"Network Issues\"]\n",
    "filtered = df.query(\"category in @categories\")\n",
    "print(f\"Using query: {len(filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 4: Using isin()\n",
    "filtered = df[df[\"category\"].isin(categories)]\n",
    "print(f\"Using isin: {len(filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working with JSON in Columns\n",
    "\n",
    "Often data contains JSON strings that need parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at metadata column\n",
    "print(\"Raw metadata:\")\n",
    "print(df[\"metadata\"].iloc[0])\n",
    "print(\"\\nParsed:\")\n",
    "print(json.loads(df[\"metadata\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract status from metadata\n",
    "def extract_status(metadata_str):\n",
    "    \"\"\"Extract status from metadata JSON list.\"\"\"\n",
    "    try:\n",
    "        metadata = json.loads(metadata_str)\n",
    "        for item in metadata:\n",
    "            if \"status\" in item:\n",
    "                return item[\"status\"]\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df[\"status\"] = df[\"metadata\"].apply(extract_status)\n",
    "print(df[[\"id\", \"status\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by extracted status\n",
    "resolved = df[df[\"status\"] == \"resolved\"]\n",
    "print(f\"Resolved tickets: {len(resolved)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transformations with apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add description length\n",
    "df[\"desc_length\"] = df[\"description\"].apply(len)\n",
    "print(df[[\"id\", \"desc_length\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized alternative (faster)\n",
    "df[\"desc_length\"] = df[\"description\"].str.len()\n",
    "print(df[\"desc_length\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply with multiple columns\n",
    "def create_summary(row):\n",
    "    return f\"{row['category']}: {row['description'][:50]}...\"\n",
    "\n",
    "df[\"summary\"] = df.apply(create_summary, axis=1)\n",
    "print(df[\"summary\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic groupby\n",
    "category_stats = df.groupby(\"category\").agg(\n",
    "    ticket_count=(\"id\", \"count\"),\n",
    "    avg_desc_length=(\"desc_length\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "print(category_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by multiple columns\n",
    "grouped = df.groupby([\"category\", \"status\"]).size().reset_index(name=\"count\")\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform - add group statistics to each row\n",
    "df[\"category_avg_length\"] = df.groupby(\"category\")[\"desc_length\"].transform(\"mean\")\n",
    "df[\"vs_category_avg\"] = df[\"desc_length\"] - df[\"category_avg_length\"]\n",
    "print(df[[\"category\", \"desc_length\", \"category_avg_length\", \"vs_category_avg\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lookup table\n",
    "priority_lookup = pd.DataFrame({\n",
    "    \"category\": [\"Software Installation\", \"Network Issues\", \"Hardware\", \"Email\"],\n",
    "    \"priority\": [2, 3, 1, 2],\n",
    "    \"team\": [\"IT Support\", \"Network Team\", \"Hardware Team\", \"IT Support\"]\n",
    "})\n",
    "\n",
    "print(\"Lookup table:\")\n",
    "print(priority_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge - LEFT JOIN\n",
    "df_enriched = pd.merge(\n",
    "    df,\n",
    "    priority_lookup,\n",
    "    on=\"category\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(df_enriched[[\"id\", \"category\", \"priority\", \"team\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: map() for single column lookup (faster)\n",
    "priority_dict = priority_lookup.set_index(\"category\")[\"priority\"].to_dict()\n",
    "df[\"priority\"] = df[\"category\"].map(priority_dict)\n",
    "print(df[[\"category\", \"priority\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key operations covered:\n",
    "- `pd.read_csv()` / `pd.read_json()` - loading data\n",
    "- Boolean indexing, `query()`, `isin()` - filtering\n",
    "- `apply()`, `.str` accessor - transformations\n",
    "- `groupby()`, `agg()`, `transform()` - aggregation\n",
    "- `merge()`, `map()` - joining data\n",
    "\n",
    "### Practice:\n",
    "Now try the tasks in `../tasks/` folder!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
