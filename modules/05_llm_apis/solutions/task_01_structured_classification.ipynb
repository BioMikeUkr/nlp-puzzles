{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Structured Classification and Extraction - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import Literal, List, Optional\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "# SET YOUR API KEY\n",
    "api_key = \"your_api_key_here\"\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('../fixtures/input/support_tickets.json', 'r') as f:\n",
    "    tickets = json.load(f)\n",
    "\n",
    "with open('../fixtures/input/extraction_texts.json', 'r') as f:\n",
    "    extraction_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(tickets)} tickets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Define Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "class Priority(str, Enum):\n",
    "    LOW = \"low\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HIGH = \"high\"\n",
    "    URGENT = \"urgent\"\n",
    "\n",
    "class TicketClassification(BaseModel):\n",
    "    category: Literal[\n",
    "        \"technical\",\n",
    "        \"billing\",\n",
    "        \"account\",\n",
    "        \"feature_request\",\n",
    "        \"bug_report\",\n",
    "        \"general\"\n",
    "    ]\n",
    "    priority: Priority\n",
    "    subcategory: str = Field(max_length=50)\n",
    "    estimated_hours: int = Field(ge=0, le=720)\n",
    "    requires_escalation: bool\n",
    "    confidence: float = Field(ge=0, le=1)\n",
    "    reasoning: str = Field(min_length=10, max_length=200)\n",
    "\n",
    "print(\"✓ Schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Classify Single Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "ticket = tickets[0]\n",
    "ticket_text = f\"{ticket['subject']}\\n{ticket['body']}\"\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a support ticket classifier.\n",
    "Classify tickets into categories and assign priority.\n",
    "\n",
    "Priority guidelines:\n",
    "- urgent: System down, security issues, data loss\n",
    "- high: Major features broken, paying customers affected\n",
    "- medium: Features not working, workarounds exist\n",
    "- low: Questions, minor issues, feature requests\"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Classify: {ticket_text}\"}\n",
    "    ],\n",
    "    response_format=TicketClassification\n",
    ")\n",
    "\n",
    "classification = response.choices[0].message.parsed\n",
    "\n",
    "print(f\"Category: {classification.category}\")\n",
    "print(f\"Priority: {classification.priority.value}\")\n",
    "print(f\"Reasoning: {classification.reasoning}\")\n",
    "print(\"✓ Task 2 passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Batch Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "results = []\n",
    "total_input_tokens = 0\n",
    "total_output_tokens = 0\n",
    "\n",
    "for ticket in tickets:\n",
    "    ticket_text = f\"{ticket['subject']}\\n{ticket['body']}\"\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Classify support tickets.\"},\n",
    "            {\"role\": \"user\", \"content\": ticket_text}\n",
    "        ],\n",
    "        response_format=TicketClassification\n",
    "    )\n",
    "\n",
    "    classification = response.choices[0].message.parsed\n",
    "    results.append({\n",
    "        \"ticket_id\": ticket['ticket_id'],\n",
    "        \"classification\": classification\n",
    "    })\n",
    "\n",
    "    # Track usage\n",
    "    total_input_tokens += response.usage.prompt_tokens\n",
    "    total_output_tokens += response.usage.completion_tokens\n",
    "\n",
    "# Calculate cost (gpt-4o-mini pricing)\n",
    "total_cost = (\n",
    "    (total_input_tokens / 1_000_000) * 0.15 +\n",
    "    (total_output_tokens / 1_000_000) * 0.60\n",
    ")\n",
    "\n",
    "print(f\"Classified {len(results)} tickets\")\n",
    "print(f\"Total tokens: {total_input_tokens + total_output_tokens}\")\n",
    "print(f\"Total cost: ${total_cost:.4f}\")\n",
    "print(\"✓ Task 3 passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Measure Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "category_correct = 0\n",
    "priority_correct = 0\n",
    "\n",
    "for ticket, result in zip(tickets, results):\n",
    "    predicted = result['classification']\n",
    "\n",
    "    if predicted.category == ticket['expected_category']:\n",
    "        category_correct += 1\n",
    "\n",
    "    if predicted.priority.value == ticket['expected_priority']:\n",
    "        priority_correct += 1\n",
    "\n",
    "category_accuracy = category_correct / len(tickets)\n",
    "priority_accuracy = priority_correct / len(tickets)\n",
    "\n",
    "print(f\"Category accuracy: {category_accuracy:.1%}\")\n",
    "print(f\"Priority accuracy: {priority_accuracy:.1%}\")\n",
    "print(\"✓ Task 4 passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Contact Extraction Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "import re\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    name: str = Field(min_length=1, max_length=100)\n",
    "    company: Optional[str] = Field(None, max_length=100)\n",
    "    email: Optional[str] = None\n",
    "    phone: Optional[str] = None\n",
    "    interest: Optional[str] = None\n",
    "\n",
    "    @field_validator('email')\n",
    "    def validate_email(cls, v):\n",
    "        if v and not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', v):\n",
    "            raise ValueError('Invalid email format')\n",
    "        return v.lower() if v else v\n",
    "\n",
    "print(\"✓ Task 5 passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Extract Contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "extraction_results = []\n",
    "\n",
    "for item in extraction_data[:3]:\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract contact information.\"},\n",
    "            {\"role\": \"user\", \"content\": item['text']}\n",
    "        ],\n",
    "        response_format=ContactInfo\n",
    "    )\n",
    "\n",
    "    contact = response.choices[0].message.parsed\n",
    "    extraction_results.append(contact)\n",
    "\n",
    "print(\"✓ Task 6 passed\")\n",
    "for i, contact in enumerate(extraction_results):\n",
    "    print(f\"\\n{i+1}. {contact.name} - {contact.email}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=1000)\n",
    "def classify_ticket_cached(ticket_text: str) -> TicketClassification:\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Classify tickets.\"},\n",
    "            {\"role\": \"user\", \"content\": ticket_text}\n",
    "        ],\n",
    "        response_format=TicketClassification\n",
    "    )\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "test_ticket = \"Urgent: System down!\"\n",
    "result1 = classify_ticket_cached(test_ticket)\n",
    "result2 = classify_ticket_cached(test_ticket)\n",
    "\n",
    "print(f\"Cache info: {classify_ticket_cached.cache_info()}\")\n",
    "print(\"✓ Task 7 passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "from openai import APIError, RateLimitError\n",
    "from pydantic import ValidationError\n",
    "\n",
    "def safe_classify(ticket_text: str):\n",
    "    try:\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Classify tickets.\"},\n",
    "                {\"role\": \"user\", \"content\": ticket_text}\n",
    "            ],\n",
    "            response_format=TicketClassification\n",
    "        )\n",
    "        return response.choices[0].message.parsed, None\n",
    "\n",
    "    except RateLimitError:\n",
    "        return None, \"Rate limit exceeded\"\n",
    "\n",
    "    except APIError as e:\n",
    "        return None, f\"API error: {str(e)}\"\n",
    "\n",
    "    except ValidationError as e:\n",
    "        return None, f\"Validation error: {str(e)}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, f\"Unexpected error: {str(e)}\"\n",
    "\n",
    "result, error = safe_classify(\"Test ticket\")\n",
    "print(\"✓ Task 8 passed\")\n",
    "if result:\n",
    "    print(f\"  Classification: {result.category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Achievements:**\n",
    "- ✓ Pydantic schemas with validation\n",
    "- ✓ Structured outputs for classification\n",
    "- ✓ Information extraction\n",
    "- ✓ Cost tracking\n",
    "- ✓ Accuracy measurement\n",
    "- ✓ Caching for efficiency\n",
    "- ✓ Production error handling\n",
    "\n",
    "**Key learnings:**\n",
    "- Structured outputs eliminate parsing logic\n",
    "- Pydantic provides automatic validation\n",
    "- Token tracking enables cost monitoring\n",
    "- Caching reduces API calls by 50-90%\n",
    "- Error handling is critical for production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
