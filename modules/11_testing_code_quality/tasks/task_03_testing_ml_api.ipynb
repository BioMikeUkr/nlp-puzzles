{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f68093",
   "metadata": {},
   "source": [
    "# Task 03 — Testing ML API End-to-End\n",
    "\n",
    "Test the FastAPI app from `sample_fastapi_app.py` using TestClient and mocking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b92e7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "FIXTURES = os.path.abspath(os.path.join(\"..\", \"fixtures\", \"input\"))\n",
    "if not os.path.exists(FIXTURES):\n",
    "    FIXTURES = os.path.abspath(os.path.join(\"fixtures\", \"input\"))\n",
    "sys.path.insert(0, FIXTURES)\n",
    "\n",
    "from fastapi.testclient import TestClient\n",
    "from unittest.mock import MagicMock\n",
    "from sample_fastapi_app import app, ml_models\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f47b1d8",
   "metadata": {},
   "source": [
    "## Task 3.1: Test Health Endpoint\n",
    "\n",
    "Write tests that verify:\n",
    "- `/health` returns 200\n",
    "- Response has `status` = \"ok\" and `model_loaded` = True\n",
    "- Use `TestClient` with context manager (required for lifespan!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# with TestClient(app) as client:\n",
    "#     ...\n",
    "\n",
    "# TEST — Do not modify\n",
    "with TestClient(app) as client:\n",
    "    resp = client.get(\"/health\")\n",
    "    assert resp.status_code == 200\n",
    "    assert resp.json()[\"status\"] == \"ok\"\n",
    "    assert resp.json()[\"model_loaded\"] is True\n",
    "print(\"Task 3.1 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1f3fc",
   "metadata": {},
   "source": [
    "## Task 3.2: Test Predict Endpoint\n",
    "\n",
    "Write tests for `/predict`:\n",
    "- Positive text returns a valid prediction\n",
    "- Response has `label`, `score`, and `text` fields\n",
    "- Score is between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Test the /predict endpoint with a positive text\n",
    "\n",
    "# TEST — Do not modify\n",
    "with TestClient(app) as client:\n",
    "    resp = client.post(\"/predict\", json={\"text\": \"This is amazing and great\"})\n",
    "    assert resp.status_code == 200\n",
    "    data = resp.json()\n",
    "    assert \"label\" in data\n",
    "    assert \"score\" in data\n",
    "    assert \"text\" in data\n",
    "    assert 0 <= data[\"score\"] <= 1\n",
    "    assert data[\"text\"] == \"This is amazing and great\"\n",
    "print(\"Task 3.2 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e537afb0",
   "metadata": {},
   "source": [
    "## Task 3.3: Test Validation Errors\n",
    "\n",
    "Write tests that verify the API returns 422 for:\n",
    "- Empty text `{\"text\": \"\"}`\n",
    "- Missing text field `{}`\n",
    "- Text too long (over 5000 chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f68f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# TEST — Do not modify\n",
    "with TestClient(app) as client:\n",
    "    assert client.post(\"/predict\", json={\"text\": \"\"}).status_code == 422\n",
    "    assert client.post(\"/predict\", json={}).status_code == 422\n",
    "    assert client.post(\"/predict\", json={\"text\": \"x\" * 5001}).status_code == 422\n",
    "print(\"Task 3.3 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59564500",
   "metadata": {},
   "source": [
    "## Task 3.4: Test Batch Predict\n",
    "\n",
    "Write tests for `/predict/batch`:\n",
    "- Send 3 texts, get 3 predictions back\n",
    "- Each prediction has the required fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1433384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# TEST — Do not modify\n",
    "with TestClient(app) as client:\n",
    "    texts = [\"good product\", \"terrible service\", \"it was okay\"]\n",
    "    resp = client.post(\"/predict/batch\", json={\"texts\": texts})\n",
    "    assert resp.status_code == 200\n",
    "    preds = resp.json()[\"predictions\"]\n",
    "    assert len(preds) == 3\n",
    "    for p in preds:\n",
    "        assert \"label\" in p and \"score\" in p and \"text\" in p\n",
    "print(\"Task 3.4 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf90e4d1",
   "metadata": {},
   "source": [
    "## Task 3.5: Mock the ML Model\n",
    "\n",
    "Replace the sentiment model with a `MagicMock` that always returns `(\"positive\", 0.99)`.\n",
    "Verify that the mock is used and the response matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8971e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Hint:\n",
    "# mock_model = MagicMock()\n",
    "# mock_model.predict.return_value = (\"positive\", 0.99)\n",
    "# ml_models[\"sentiment\"] = mock_model\n",
    "# Then make a request and verify the response\n",
    "\n",
    "# TEST — Do not modify\n",
    "with TestClient(app) as client:\n",
    "    mock_model = MagicMock()\n",
    "    mock_model.predict.return_value = (\"positive\", 0.99)\n",
    "    ml_models[\"sentiment\"] = mock_model\n",
    "\n",
    "    resp = client.post(\"/predict\", json={\"text\": \"any text here\"})\n",
    "    assert resp.status_code == 200\n",
    "    assert resp.json()[\"label\"] == \"positive\"\n",
    "    assert resp.json()[\"score\"] == 0.99\n",
    "    mock_model.predict.assert_called_once_with(\"any text here\")\n",
    "print(\"Task 3.5 passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995e8af",
   "metadata": {},
   "source": [
    "## Task 3.6: Test Model Not Loaded (503)\n",
    "\n",
    "Clear `ml_models` so there's no model, then verify `/predict` returns 503."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c2c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Hint: manually clear ml_models after lifespan loads\n",
    "# ml_models.clear()\n",
    "\n",
    "# TEST — Do not modify\n",
    "with TestClient(app) as client:\n",
    "    ml_models.clear()\n",
    "    resp = client.post(\"/predict\", json={\"text\": \"hello\"})\n",
    "    assert resp.status_code == 503\n",
    "    assert \"not loaded\" in resp.json()[\"detail\"].lower()\n",
    "print(\"Task 3.6 passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
