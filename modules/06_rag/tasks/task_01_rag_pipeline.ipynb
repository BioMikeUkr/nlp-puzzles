{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Build RAG Pipeline\n",
    "\n",
    "Build complete RAG system with chunking, indexing, retrieval, and generation.\n",
    "\n",
    "**Goals:**\n",
    "- Chunk documents\n",
    "- Build FAISS index\n",
    "- Implement retrieval\n",
    "- Generate answers with LLM\n",
    "- Add citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "**Set your OpenAI API key:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"your-api-key-here\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "with open('../fixtures/input/documents.json', 'r') as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Chunk Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Create RecursiveCharacterTextSplitter (chunk_size=600, overlap=120)\n",
    "# 2. Chunk all documents\n",
    "# 3. Store chunks with metadata (source, doc_id, chunk_id)\n",
    "\n",
    "splitter = None  # TODO\n",
    "all_chunks = []  # TODO\n",
    "\n",
    "# TEST\n",
    "assert len(all_chunks) > 0, \"No chunks created\"\n",
    "assert 'text' in all_chunks[0], \"Missing text field\"\n",
    "assert 'source' in all_chunks[0], \"Missing source field\"\n",
    "print(f\"✓ Task 1 passed: {len(all_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Build FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Generate embeddings for all chunks\n",
    "# 2. Create FAISS IndexFlatIP\n",
    "# 3. Add embeddings to index\n",
    "\n",
    "embeddings = None  # TODO\n",
    "index = None  # TODO\n",
    "\n",
    "# TEST\n",
    "assert index is not None, \"Index not created\"\n",
    "assert index.ntotal == len(all_chunks), \"Wrong number of vectors\"\n",
    "print(f\"✓ Task 2 passed: indexed {index.ntotal} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Implement Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create retrieve function that:\n",
    "# 1. Embeds query\n",
    "# 2. Searches FAISS index\n",
    "# 3. Returns top-k chunks with scores\n",
    "\n",
    "def retrieve(query: str, k: int = 5):\n",
    "    pass  # TODO\n",
    "\n",
    "# TEST\n",
    "results = retrieve(\"What is Python?\", k=3)\n",
    "assert len(results) == 3, \"Wrong number of results\"\n",
    "assert 'text' in results[0], \"Missing text in result\"\n",
    "print(\"✓ Task 3 passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Implement RAG with Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create rag function that:\n",
    "# 1. Retrieves relevant chunks\n",
    "# 2. Builds context with citations [1], [2], etc.\n",
    "# 3. Generates answer with LLM\n",
    "# 4. Returns answer and sources\n",
    "\n",
    "def rag(question: str, k: int = 5):\n",
    "    pass  # TODO\n",
    "\n",
    "# TEST\n",
    "result = rag(\"What is Python?\")\n",
    "assert 'answer' in result, \"Missing answer\"\n",
    "assert 'sources' in result, \"Missing sources\"\n",
    "print(\"✓ Task 4 passed\")\n",
    "print(f\"Answer: {result['answer'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Test on Multiple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Load test queries and test RAG on each\n",
    "# Measure accuracy (correct document retrieved)\n",
    "\n",
    "with open('../fixtures/input/test_queries.json', 'r') as f:\n",
    "    test_queries = json.load(f)\n",
    "\n",
    "accuracy = 0.0  # TODO: Calculate accuracy\n",
    "\n",
    "# TEST\n",
    "assert accuracy > 0, \"Accuracy not calculated\"\n",
    "print(f\"✓ Task 5 passed: {accuracy:.1%} accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✓ Chunked documents  \n",
    "✓ Built FAISS index  \n",
    "✓ Implemented retrieval  \n",
    "✓ Added LLM generation  \n",
    "✓ Tracked citations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
