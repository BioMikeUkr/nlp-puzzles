{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Sentence Transformers\n",
    "\n",
    "Learn to adapt pre-trained models to your domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Fine-tune?\n",
    "\n",
    "Generic models work well, but fine-tuning improves performance on your specific domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generic model\n",
    "generic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Test on domain-specific query\n",
    "query = \"API authentication method\"\n",
    "docs = [\n",
    "    \"Use Bearer token in Authorization header for API authentication\",  # Relevant\n",
    "    \"Annual subscriptions get 20% discount\",  # Not relevant\n",
    "    \"Python is a programming language\"  # Not relevant\n",
    "]\n",
    "\n",
    "# Embed\n",
    "query_emb = generic_model.encode(query)\n",
    "doc_embs = generic_model.encode(docs)\n",
    "\n",
    "# Calculate similarities\n",
    "similarities = cosine_similarity([query_emb], doc_embs)[0]\n",
    "\n",
    "print(\"Generic model similarities:\")\n",
    "for i, (doc, sim) in enumerate(zip(docs, similarities)):\n",
    "    print(f\"{i+1}. [{sim:.3f}] {doc[:50]}...\")\n",
    "\n",
    "print(\"\\n⚠️  Generic model may not capture domain-specific relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load extended training pairs (100 examples)\nwith open('../fixtures/input/training_pairs_extended.json', 'r') as f:\n    training_data = json.load(f)\n\nprint(f\"Loaded {len(training_data)} training examples\\n\")\n\n# Show example\nexample = training_data[0]\nprint(\"Training example:\")\nprint(f\"  Query: {example['query']}\")\nprint(f\"  Positive: {example['positive']}\")\nprint(f\"  Negative: {example['negative']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Examples\n",
    "\n",
    "Convert to InputExample format for sentence-transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create InputExample objects\n",
    "train_examples = []\n",
    "\n",
    "for item in training_data:\n",
    "    # Positive pair (query, positive_doc)\n",
    "    train_examples.append(\n",
    "        InputExample(texts=[item['query'], item['positive']])\n",
    "    )\n",
    "\n",
    "print(f\"Created {len(train_examples)} training examples\")\n",
    "print(f\"\\nExample format: {train_examples[0].texts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create DataLoader for batching\ntrain_dataloader = DataLoader(\n    train_examples,\n    shuffle=True,\n    batch_size=16  # Larger batch for 100 examples\n)\n\nprint(f\"DataLoader created:\")\nprint(f\"  Batch size: 16\")\nprint(f\"  Number of batches: {len(train_dataloader)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Loss Function\n",
    "\n",
    "MultipleNegativesRankingLoss is best for retrieval tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model to fine-tune\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define loss function\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "print(\"✓ Loss function: MultipleNegativesRankingLoss\")\n",
    "print(\"  Uses other batch examples as negatives\")\n",
    "print(\"  Efficient for retrieval tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate warmup steps (10% of total)\n",
    "num_epochs = 3\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Epochs: {num_epochs}\")\n",
    "print(f\"  Total steps: {total_steps}\")\n",
    "print(f\"  Warmup steps: {warmup_steps}\")\n",
    "\n",
    "# Fine-tune\n",
    "print(\"\\nStarting fine-tuning...\\n\")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='../output/fine_tuned_model',\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fine-tuned model\n",
    "finetuned_model = SentenceTransformer('../output/fine_tuned_model')\n",
    "\n",
    "# Test on same query as before\n",
    "query = \"API authentication method\"\n",
    "docs = [\n",
    "    \"Use Bearer token in Authorization header for API authentication\",\n",
    "    \"Annual subscriptions get 20% discount\",\n",
    "    \"Python is a programming language\"\n",
    "]\n",
    "\n",
    "# Generic model\n",
    "generic_emb = generic_model.encode(query)\n",
    "generic_doc_embs = generic_model.encode(docs)\n",
    "generic_sims = cosine_similarity([generic_emb], generic_doc_embs)[0]\n",
    "\n",
    "# Fine-tuned model\n",
    "finetuned_emb = finetuned_model.encode(query)\n",
    "finetuned_doc_embs = finetuned_model.encode(docs)\n",
    "finetuned_sims = cosine_similarity([finetuned_emb], finetuned_doc_embs)[0]\n",
    "\n",
    "print(\"Comparison:\")\n",
    "print(\"\\nGeneric Model:\")\n",
    "for i, (doc, sim) in enumerate(zip(docs, generic_sims)):\n",
    "    print(f\"  {i+1}. [{sim:.3f}] {doc[:50]}...\")\n",
    "\n",
    "print(\"\\nFine-tuned Model:\")\n",
    "for i, (doc, sim) in enumerate(zip(docs, finetuned_sims)):\n",
    "    print(f\"  {i+1}. [{sim:.3f}] {doc[:50]}...\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement = finetuned_sims[0] - generic_sims[0]\n",
    "print(f\"\\n✓ Improvement on relevant doc: +{improvement:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test on multiple queries\n",
    "test_queries = [\n",
    "    (\"password reset\", \"To reset password click Forgot Password\", \"Pricing starts at $29\"),\n",
    "    (\"pricing info\", \"Professional plan costs $99/month\", \"Reset password from settings\"),\n",
    "    (\"vacation days\", \"New employees get 15 vacation days\", \"API uses Bearer tokens\")\n",
    "]\n",
    "\n",
    "generic_scores = []\n",
    "finetuned_scores = []\n",
    "\n",
    "for query, relevant, irrelevant in test_queries:\n",
    "    # Generic\n",
    "    q_emb = generic_model.encode(query)\n",
    "    rel_emb = generic_model.encode(relevant)\n",
    "    generic_score = cosine_similarity([q_emb], [rel_emb])[0][0]\n",
    "    generic_scores.append(generic_score)\n",
    "\n",
    "    # Fine-tuned\n",
    "    q_emb = finetuned_model.encode(query)\n",
    "    rel_emb = finetuned_model.encode(relevant)\n",
    "    finetuned_score = cosine_similarity([q_emb], [rel_emb])[0][0]\n",
    "    finetuned_scores.append(finetuned_score)\n",
    "\n",
    "# Plot\n",
    "x = np.arange(len(test_queries))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.bar(x - width/2, generic_scores, width, label='Generic')\n",
    "ax.bar(x + width/2, finetuned_scores, width, label='Fine-tuned')\n",
    "\n",
    "ax.set_ylabel('Similarity Score')\n",
    "ax.set_title('Generic vs Fine-tuned Model Performance')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f\"Query {i+1}\" for i in range(len(test_queries))])\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "avg_improvement = np.mean(np.array(finetuned_scores) - np.array(generic_scores))\n",
    "print(f\"\\nAverage improvement: +{avg_improvement:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model already saved during training\n",
    "# Can also save manually:\n",
    "# model.save('../output/my_fine_tuned_model')\n",
    "\n",
    "# Load later:\n",
    "# loaded_model = SentenceTransformer('../output/fine_tuned_model')\n",
    "\n",
    "print(\"✓ Model saved at: ../output/fine_tuned_model\")\n",
    "print(\"  Use: SentenceTransformer('../output/fine_tuned_model')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\n✅ Prepared training data in InputExample format  \n✅ Used MultipleNegativesRankingLoss for retrieval  \n✅ Fine-tuned model with warmup  \n✅ Tested improvements  \n✅ Saved model\n\n**Key learnings:**\n- Fine-tuning improves domain-specific performance\n- 100 examples show significant improvement\n- MultipleNegativesRankingLoss best for retrieval\n- Warmup stabilizes training\n- More data = better results\n\n**Next steps:**\n- Try TripletLoss for explicit triplets (notebook 02)\n- Experiment with ContrastiveLoss (notebook 03)\n- Learn full Transformers Trainer API (notebook 04)\n- Compare all approaches (notebook 05)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}