{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning with Triplet Loss\n",
    "\n",
    "Learn to use triplet loss for metric learning and semantic similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Triplet Loss?\n",
    "\n",
    "Triplet loss learns embeddings by comparing:\n",
    "- **Anchor**: Reference text\n",
    "- **Positive**: Similar text (should be close)\n",
    "- **Negative**: Different text (should be far)\n",
    "\n",
    "**Goal**: `distance(anchor, positive) < distance(anchor, negative) + margin`\n",
    "\n",
    "```\n",
    "Anchor: \"How to reset password?\"\n",
    "Positive: \"Click forgot password link\"  â† Should be CLOSE\n",
    "Negative: \"Pricing plans start at $29\"  â† Should be FAR\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Triplet Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load hard triplets (500 examples with challenging negatives)\nwith open('../fixtures/input/training_triplets_hard.json', 'r') as f:\n    triplets = json.load(f)\n\nprint(f\"Loaded {len(triplets)} hard triplet examples\\n\")\n\n# Show example\nexample = triplets[0]\nprint(\"Triplet structure:\")\nprint(f\"  Anchor:   {example['anchor']}\")\nprint(f\"  Positive: {example['positive']}\")\nprint(f\"  Negative: {example['negative']}\")\n\nprint(\"\\nðŸ’¡ Hard negatives are semantically similar but not relevant\")\nprint(\"   This makes training more challenging and effective!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Generic Model Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load generic model\n",
    "generic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Test on sample triplet\n",
    "triplet = triplets[0]\n",
    "anchor_emb = generic_model.encode(triplet['anchor'])\n",
    "positive_emb = generic_model.encode(triplet['positive'])\n",
    "negative_emb = generic_model.encode(triplet['negative'])\n",
    "\n",
    "# Calculate distances\n",
    "pos_sim = cosine_similarity([anchor_emb], [positive_emb])[0][0]\n",
    "neg_sim = cosine_similarity([anchor_emb], [negative_emb])[0][0]\n",
    "\n",
    "print(\"Generic model similarities:\")\n",
    "print(f\"  Anchor â†” Positive: {pos_sim:.3f}\")\n",
    "print(f\"  Anchor â†” Negative: {neg_sim:.3f}\")\n",
    "print(f\"  Margin (pos - neg): {(pos_sim - neg_sim):.3f}\")\n",
    "\n",
    "if pos_sim - neg_sim < 0.2:\n",
    "    print(\"\\nâš ï¸  Margin too small - model doesn't distinguish well!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Triplet Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create InputExample objects for triplets\n",
    "train_examples = []\n",
    "\n",
    "for item in triplets:\n",
    "    train_examples.append(\n",
    "        InputExample(\n",
    "            texts=[item['anchor'], item['positive'], item['negative']]\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(f\"Created {len(train_examples)} triplet training examples\")\n",
    "print(f\"\\nExample format: {len(train_examples[0].texts)} texts per triplet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 80/20 for train/validation\n",
    "split_idx = int(0.8 * len(train_examples))\n",
    "train_data = train_examples[:split_idx]\n",
    "val_data = train_examples[split_idx:]\n",
    "\n",
    "print(f\"Training examples: {len(train_data)}\")\n",
    "print(f\"Validation examples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoader with Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created:\")\n",
    "print(f\"  Batch size: 16\")\n",
    "print(f\"  Number of batches: {len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Triplet Loss\n",
    "\n",
    "**TripletLoss parameters:**\n",
    "- `distance_metric`: How to measure distance (cosine, euclidean)\n",
    "- `triplet_margin`: Minimum separation between positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model to fine-tune\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define triplet loss with margin\n",
    "train_loss = losses.TripletLoss(\n",
    "    model=model,\n",
    "    distance_metric=losses.TripletDistanceMetric.COSINE,\n",
    "    triplet_margin=0.5  # Positive should be 0.5 closer than negative\n",
    ")\n",
    "\n",
    "print(\"âœ“ Loss function: TripletLoss\")\n",
    "print(\"  Distance metric: Cosine\")\n",
    "print(\"  Margin: 0.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluator from validation data\n",
    "anchors = [ex.texts[0] for ex in val_data]\n",
    "positives = [ex.texts[1] for ex in val_data]\n",
    "negatives = [ex.texts[2] for ex in val_data]\n",
    "\n",
    "evaluator = TripletEvaluator(\n",
    "    anchors=anchors,\n",
    "    positives=positives,\n",
    "    negatives=negatives,\n",
    "    name='triplet_eval'\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Evaluator created with {len(val_data)} validation triplets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune with Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Training configuration\nnum_epochs = 4  # Reduced for 500 examples - more data needs fewer epochs\nwarmup_steps = int(0.1 * len(train_dataloader) * num_epochs)\neval_steps = max(50, len(train_dataloader) // 4)  # Evaluate 4 times per epoch\n\nprint(f\"Training configuration:\")\nprint(f\"  Total examples: {len(train_data)} (hard negatives)\")\nprint(f\"  Epochs: {num_epochs}\")\nprint(f\"  Warmup steps: {warmup_steps}\")\nprint(f\"  Evaluation frequency: every {eval_steps} steps\")\nprint(f\"  Total training steps: {len(train_dataloader) * num_epochs}\")\n\n# Evaluate before training\nprint(\"\\n\" + \"=\"*60)\nprint(\"INITIAL EVALUATION (before training)\")\nprint(\"=\"*60)\ninitial_result = evaluator(model, output_path='../output/triplet_finetuned_model')\n# TripletEvaluator returns dict like {'triplet_eval_cosine_accuracy': 0.98}\nif isinstance(initial_result, dict):\n    initial_score = list(initial_result.values())[0]\nelse:\n    initial_score = initial_result\nprint(f\"Initial Accuracy: {initial_score:.4f}\")\nprint(f\"  (1.0 = perfect, 0.5 = random)\")\nprint(\"=\"*60 + \"\\n\")\n\n# Fine-tune\nprint(\"Starting fine-tuning with triplet loss on HARD examples...\")\nprint(\"Watch for evaluation outputs below:\\n\")\n\nmodel.fit(\n    train_objectives=[(train_dataloader, train_loss)],\n    epochs=num_epochs,\n    warmup_steps=warmup_steps,\n    evaluator=evaluator,\n    evaluation_steps=eval_steps,  # Evaluate more frequently\n    output_path='../output/triplet_finetuned_model',\n    show_progress_bar=True,\n    save_best_model=True,  # Only save best model\n    use_amp=False,  # Disable mixed precision for stability\n    checkpoint_save_steps=10000,  # Don't save intermediate checkpoints\n    checkpoint_save_total_limit=1,  # Keep only best model\n    optimizer_params={'lr': 2e-5}  # Learning rate for better convergence\n)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"âœ“ Fine-tuning complete!\")\nprint(\"=\"*60)\n\n# Load and display final metrics\nimport pandas as pd\nimport os\n\n# NOTE: sentence-transformers saves evaluation results to 'eval/' subfolder\n# with prefix from evaluator class name (e.g., 'triplet_evaluation_')\nmetrics_file = '../output/triplet_finetuned_model/eval/triplet_evaluation_triplet_eval_results.csv'\nif os.path.exists(metrics_file):\n    print(\"\\n\" + \"=\"*60)\n    print(\"TRAINING METRICS SUMMARY\")\n    print(\"=\"*60)\n    metrics_df = pd.read_csv(metrics_file)\n    \n    # Filter out pre-training evaluation (epoch=-1, steps=-1)\n    metrics_df = metrics_df[(metrics_df['epoch'] >= 0) & (metrics_df['steps'] >= 0)]\n    \n    # Show first, middle, and last few rows\n    print(\"\\nFirst evaluations:\")\n    print(metrics_df.head(3).to_string(index=False))\n    if len(metrics_df) > 6:\n        print(\"\\n...\")\n        print(\"\\nFinal evaluations:\")\n        print(metrics_df.tail(3).to_string(index=False))\n    \n    print(\"\\n\" + \"=\"*60)\n    # Use accuracy_cosine column instead of 'accuracy'\n    metric_col = 'accuracy_cosine' if 'accuracy_cosine' in metrics_df.columns else 'accuracy'\n    best_acc = metrics_df[metric_col].max()\n    best_step = metrics_df.loc[metrics_df[metric_col].idxmax(), 'steps']\n    improvement = best_acc - initial_score\n    improvement_pct = (improvement / initial_score * 100) if initial_score > 0 else 0\n    \n    print(f\"ðŸ“Š RESULTS:\")\n    print(f\"  Initial Accuracy:  {initial_score:.4f}\")\n    print(f\"  Best Accuracy:     {best_acc:.4f} (at step {int(best_step)})\")\n    print(f\"  Improvement:       +{improvement:.4f} ({improvement_pct:+.1f}%)\")\n    print(\"=\"*60)\n    \n    # Note about training loss\n    print(\"\\nðŸ’¡ NOTE: 'No log' in Training/Validation Loss columns is NORMAL.\")\n    print(\"   sentence-transformers logs evaluation metrics (accuracy)\")\n    print(\"   but doesn't log raw loss values in the progress bar.\")\n    print(\"   The evaluation metrics are saved to CSV and shown above.\")\n    \n    if improvement > 0.05:\n        print(\"\\nâœ… Model successfully improved on hard negatives!\")\n    elif improvement > 0:\n        print(\"\\nâš ï¸  Small improvement - hard negatives are challenging\")\n    else:\n        print(\"\\nâš ï¸  No improvement - may need more epochs or different hyperparameters\")\nelse:\n    print(\"\\nâš ï¸  Metrics file not found at:\")\n    print(f\"   {metrics_file}\")\n    print(\"   Check that the evaluator and output_path are correctly configured\")"
  },
  {
   "cell_type": "markdown",
   "source": "## Visualize Training Progress",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Plot training progress\nimport pandas as pd\nimport os\n\nmetrics_file = '../output/triplet_finetuned_model/eval/triplet_evaluation_triplet_eval_results.csv'\nif os.path.exists(metrics_file):\n    metrics_df = pd.read_csv(metrics_file)\n    \n    # Filter out pre-training evaluation (epoch=-1, steps=-1)\n    metrics_df = metrics_df[(metrics_df['epoch'] >= 0) & (metrics_df['steps'] >= 0)]\n    \n    # Use accuracy_cosine column\n    metric_col = 'accuracy_cosine' if 'accuracy_cosine' in metrics_df.columns else 'accuracy'\n    \n    fig, ax = plt.subplots(figsize=(12, 5))\n    \n    ax.plot(metrics_df['steps'], metrics_df[metric_col], marker='o', linewidth=2, markersize=6)\n    ax.axhline(initial_score, color='red', linestyle='--', label=f'Initial: {initial_score:.4f}')\n    ax.set_xlabel('Training Steps', fontsize=12)\n    ax.set_ylabel('Accuracy', fontsize=12)\n    ax.set_title('Triplet Loss Training Progress', fontsize=14, fontweight='bold')\n    ax.grid(True, alpha=0.3)\n    ax.legend()\n    \n    # Annotate best score\n    best_idx = metrics_df[metric_col].idxmax()\n    best_step = metrics_df.loc[best_idx, 'steps']\n    best_acc = metrics_df.loc[best_idx, metric_col]\n    ax.annotate(f'Best: {best_acc:.4f}', \n                xy=(best_step, best_acc),\n                xytext=(10, -20),\n                textcoords='offset points',\n                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7),\n                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"\\nAccuracy improved from {initial_score:.4f} to {best_acc:.4f}\")\n    print(f\"Total improvement: +{(best_acc - initial_score):.4f} ({((best_acc - initial_score) / initial_score * 100):.1f}%)\")\nelse:\n    print(\"âš ï¸  No metrics file found. Training may not have completed or evaluator didn't run.\")\n    print(f\"   Expected path: {metrics_file}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Before/After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fine-tuned model\n",
    "finetuned_model = SentenceTransformer('../output/triplet_finetuned_model')\n",
    "\n",
    "# Test on multiple triplets\n",
    "test_triplets = triplets[split_idx:split_idx+10]  # Use validation examples\n",
    "\n",
    "generic_margins = []\n",
    "finetuned_margins = []\n",
    "\n",
    "for triplet in test_triplets:\n",
    "    # Generic model\n",
    "    anchor_emb = generic_model.encode(triplet['anchor'])\n",
    "    pos_emb = generic_model.encode(triplet['positive'])\n",
    "    neg_emb = generic_model.encode(triplet['negative'])\n",
    "    \n",
    "    pos_sim = cosine_similarity([anchor_emb], [pos_emb])[0][0]\n",
    "    neg_sim = cosine_similarity([anchor_emb], [neg_emb])[0][0]\n",
    "    generic_margins.append(pos_sim - neg_sim)\n",
    "    \n",
    "    # Fine-tuned model\n",
    "    anchor_emb = finetuned_model.encode(triplet['anchor'])\n",
    "    pos_emb = finetuned_model.encode(triplet['positive'])\n",
    "    neg_emb = finetuned_model.encode(triplet['negative'])\n",
    "    \n",
    "    pos_sim = cosine_similarity([anchor_emb], [pos_emb])[0][0]\n",
    "    neg_sim = cosine_similarity([anchor_emb], [neg_emb])[0][0]\n",
    "    finetuned_margins.append(pos_sim - neg_sim)\n",
    "\n",
    "# Statistics\n",
    "print(\"Margin Statistics (positive - negative similarity):\")\n",
    "print(\"\\nGeneric Model:\")\n",
    "print(f\"  Mean margin: {np.mean(generic_margins):.3f}\")\n",
    "print(f\"  Std deviation: {np.std(generic_margins):.3f}\")\n",
    "print(f\"  Min margin: {np.min(generic_margins):.3f}\")\n",
    "\n",
    "print(\"\\nFine-tuned Model:\")\n",
    "print(f\"  Mean margin: {np.mean(finetuned_margins):.3f}\")\n",
    "print(f\"  Std deviation: {np.std(finetuned_margins):.3f}\")\n",
    "print(f\"  Min margin: {np.min(finetuned_margins):.3f}\")\n",
    "\n",
    "improvement = np.mean(finetuned_margins) - np.mean(generic_margins)\n",
    "print(f\"\\nâœ“ Average margin improvement: +{improvement:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Margin Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram comparison\n",
    "axes[0].hist(generic_margins, alpha=0.5, label='Generic', bins=15)\n",
    "axes[0].hist(finetuned_margins, alpha=0.5, label='Fine-tuned', bins=15)\n",
    "axes[0].axvline(0, color='red', linestyle='--', label='No separation')\n",
    "axes[0].set_xlabel('Margin (positive - negative similarity)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Margin Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Individual comparisons\n",
    "x = np.arange(len(generic_margins))\n",
    "width = 0.35\n",
    "axes[1].bar(x - width/2, generic_margins, width, label='Generic', alpha=0.7)\n",
    "axes[1].bar(x + width/2, finetuned_margins, width, label='Fine-tuned', alpha=0.7)\n",
    "axes[1].axhline(0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].set_xlabel('Test Example')\n",
    "axes[1].set_ylabel('Margin')\n",
    "axes[1].set_title('Per-Example Margins')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Higher margins = Better separation between relevant and irrelevant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Real Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on new queries\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"password recovery process\",\n",
    "        \"relevant\": \"Click forgot password and follow reset instructions\",\n",
    "        \"irrelevant\": \"Annual subscription includes priority support\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"explain machine learning concepts\",\n",
    "        \"relevant\": \"ML algorithms learn patterns from data automatically\",\n",
    "        \"irrelevant\": \"Our office is open Monday through Friday\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"API integration steps\",\n",
    "        \"relevant\": \"Add Bearer token to Authorization header for API calls\",\n",
    "        \"irrelevant\": \"Employees receive 15 vacation days per year\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Real Query Testing:\\n\")\n",
    "\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    print(f\"Test {i}: {test['query']}\")\n",
    "    \n",
    "    # Generic model\n",
    "    q_emb = generic_model.encode(test['query'])\n",
    "    rel_emb = generic_model.encode(test['relevant'])\n",
    "    irr_emb = generic_model.encode(test['irrelevant'])\n",
    "    gen_margin = (\n",
    "        cosine_similarity([q_emb], [rel_emb])[0][0] - \n",
    "        cosine_similarity([q_emb], [irr_emb])[0][0]\n",
    "    )\n",
    "    \n",
    "    # Fine-tuned model\n",
    "    q_emb = finetuned_model.encode(test['query'])\n",
    "    rel_emb = finetuned_model.encode(test['relevant'])\n",
    "    irr_emb = finetuned_model.encode(test['irrelevant'])\n",
    "    ft_margin = (\n",
    "        cosine_similarity([q_emb], [rel_emb])[0][0] - \n",
    "        cosine_similarity([q_emb], [irr_emb])[0][0]\n",
    "    )\n",
    "    \n",
    "    print(f\"  Generic margin: {gen_margin:.3f}\")\n",
    "    print(f\"  Fine-tuned margin: {ft_margin:.3f}\")\n",
    "    print(f\"  Improvement: +{(ft_margin - gen_margin):.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Select sample texts from different categories\n",
    "sample_texts = [\n",
    "    \"How to reset my password?\",\n",
    "    \"Password recovery steps\",\n",
    "    \"Login issues troubleshooting\",\n",
    "    \"What is machine learning?\",\n",
    "    \"Explain deep learning\",\n",
    "    \"Neural networks introduction\",\n",
    "    \"Professional plan pricing\",\n",
    "    \"Subscription costs\",\n",
    "    \"Payment options\"\n",
    "]\n",
    "\n",
    "categories = ['password'] * 3 + ['ml'] * 3 + ['pricing'] * 3\n",
    "\n",
    "# Encode with both models\n",
    "generic_embs = generic_model.encode(sample_texts)\n",
    "finetuned_embs = finetuned_model.encode(sample_texts)\n",
    "\n",
    "# Reduce to 2D\n",
    "pca = PCA(n_components=2)\n",
    "generic_2d = pca.fit_transform(generic_embs)\n",
    "finetuned_2d = pca.fit_transform(finetuned_embs)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "colors = {'password': 'red', 'ml': 'blue', 'pricing': 'green'}\n",
    "\n",
    "for ax, data, title in zip(\n",
    "    axes, \n",
    "    [generic_2d, finetuned_2d], \n",
    "    ['Generic Model', 'Fine-tuned Model']\n",
    "):\n",
    "    for i, (cat, text) in enumerate(zip(categories, sample_texts)):\n",
    "        ax.scatter(data[i, 0], data[i, 1], c=colors[cat], s=100, alpha=0.6)\n",
    "        ax.annotate(\n",
    "            text[:20] + '...' if len(text) > 20 else text,\n",
    "            (data[i, 0], data[i, 1]),\n",
    "            fontsize=8,\n",
    "            alpha=0.7\n",
    "        )\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=colors[cat], label=cat) \n",
    "                      for cat in ['password', 'ml', 'pricing']]\n",
    "    ax.legend(handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Fine-tuned model should show tighter clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Negative Mining (Advanced)\n",
    "\n",
    "For better training, mine hard negatives - examples that are close but wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find hard negatives\n",
    "query = \"What is machine learning?\"\n",
    "positive = \"ML learns patterns from data automatically\"\n",
    "\n",
    "# Candidate negatives\n",
    "candidates = [\n",
    "    \"Deep learning uses neural networks\",  # Hard negative (related topic)\n",
    "    \"Professional plan costs $99/month\",   # Easy negative (unrelated)\n",
    "    \"NLP processes human language\",        # Hard negative (related field)\n",
    "]\n",
    "\n",
    "# Encode\n",
    "q_emb = finetuned_model.encode(query)\n",
    "p_emb = finetuned_model.encode(positive)\n",
    "c_embs = finetuned_model.encode(candidates)\n",
    "\n",
    "# Find similarities\n",
    "pos_sim = cosine_similarity([q_emb], [p_emb])[0][0]\n",
    "print(f\"Query â†” Positive: {pos_sim:.3f}\\n\")\n",
    "\n",
    "print(\"Candidate negatives:\")\n",
    "for cand, c_emb in zip(candidates, c_embs):\n",
    "    sim = cosine_similarity([q_emb], [c_emb])[0][0]\n",
    "    difficulty = \"HARD\" if sim > 0.5 else \"EASY\"\n",
    "    print(f\"  [{sim:.3f}] {difficulty}: {cand}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Hard negatives are more informative for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… Loaded 100 triplet examples (anchor, positive, negative)  \n",
    "âœ… Used TripletLoss with cosine distance and 0.5 margin  \n",
    "âœ… Evaluated on validation set during training  \n",
    "âœ… Achieved larger margins between relevant and irrelevant  \n",
    "âœ… Visualized embedding space improvements  \n",
    "âœ… Learned about hard negative mining  \n",
    "\n",
    "**Key learnings:**\n",
    "- Triplet loss explicitly pushes apart dissimilar examples\n",
    "- Margin parameter controls minimum separation\n",
    "- Works well with 100+ triplets\n",
    "- Hard negatives (similar but wrong) improve training\n",
    "- Better clustering in embedding space\n",
    "\n",
    "**When to use Triplet Loss:**\n",
    "- Face recognition / image similarity\n",
    "- Recommendation systems\n",
    "- Semantic search with clear negatives\n",
    "- Metric learning tasks\n",
    "\n",
    "**Next:** Learn contrastive loss and compare all approaches!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}