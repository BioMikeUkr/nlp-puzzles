{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Fine-tune Sentence Transformer - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../fixtures/input/training_pairs_hard.json', 'r') as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(training_data)} training pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Prepare Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "train_examples = []\n",
    "\n",
    "for item in training_data:\n",
    "    train_examples.append(\n",
    "        InputExample(texts=[item['query'], item['positive']])\n",
    "    )\n",
    "\n",
    "print(f\"✓ Created {len(train_examples)} training examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "train_dataloader = DataLoader(\n",
    "    train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=4\n",
    ")\n",
    "\n",
    "print(\"✓ DataLoader created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Create loss\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# Calculate warmup\n",
    "num_epochs = 3\n",
    "warmup_steps = int(0.1 * len(train_dataloader) * num_epochs)\n",
    "\n",
    "# Fine-tune\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='../output/fine_tuned_model',\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"✓ Fine-tuning complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Compare Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "# Load models\n",
    "generic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "finetuned_model = SentenceTransformer('../output/fine_tuned_model')\n",
    "\n",
    "# Test pair\n",
    "query = training_data[0]['query']\n",
    "positive = training_data[0]['positive']\n",
    "\n",
    "# Generic\n",
    "generic_query_emb = generic_model.encode(query)\n",
    "generic_pos_emb = generic_model.encode(positive)\n",
    "generic_sim = cosine_similarity([generic_query_emb], [generic_pos_emb])[0][0]\n",
    "\n",
    "# Fine-tuned\n",
    "finetuned_query_emb = finetuned_model.encode(query)\n",
    "finetuned_pos_emb = finetuned_model.encode(positive)\n",
    "finetuned_sim = cosine_similarity([finetuned_query_emb], [finetuned_pos_emb])[0][0]\n",
    "\n",
    "improvement = finetuned_sim - generic_sim\n",
    "\n",
    "print(f\"Generic similarity: {generic_sim:.3f}\")\n",
    "print(f\"Fine-tuned similarity: {finetuned_sim:.3f}\")\n",
    "print(f\"Improvement: +{improvement:.3f}\")\n",
    "print(\"✓ Task 4 passed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
